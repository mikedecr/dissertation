## Testing the Model with Simulated Data {#sec:test-static}

<!-- in chapter: model -->


```{r stopper, eval = TRUE, cache = FALSE, include = FALSE}
knitr::knit_exit()
```

```{r knitr-02-1_model-sim, include = FALSE, cache = FALSE}
source(here::here("assets-bookdown", "knitr-helpers.R"))
```

```{r, cache = FALSE}
knitr::knit_exit()
```

```{r r-02-1_model-sim, cache = FALSE}
library("here")
library("magrittr")
library("tidyverse")
# library("boxr"); box_auth()

library("scales")
library("english")
library("latex2exp")
library("ggforce")

library("broom")
library("tidybayes")
```


```{r 021-helper-vars}
# helper variables
sim_seed <- 01110011
```


Because the model is custom-built with `Stan`, it comes with no off-the-shelf quality assurances. To test the model's ability to estimate unknown parameters, I subject the model to a number of tests during its development. These tests proceed by simulating data from a data generating process with known parameters, fitting the model to the simulated data, and comparing the posterior estimates against their known values. This section describes these simulations and presents their results.


```{r read-simulation-data}
# (1) read objects as list
# (2) save in GlobalEnv
# (3) remove list

# box_read(524570617700)
here("data", "mcmc", "dgirt", "test", "input", "sim-params.RDS") %>%
  readRDS() %>% 
  list2env(envir = .GlobalEnv)

ls()
```


```{r read-test-stanfit}
# box_read(507153233559)
stanfit <- readRDS(here("data", "mcmc", "dgirt", "test", "samples", "test-homsk-stanfit.RDS"))
```

```{r tidybayes-tidy}
df_stanfit <- tidy_draws(stanfit)
```

```{r read-test-stanpars, cache = FALSE}
here("data", "mcmc", "dgirt", "test", "input", "mcmc-params.RDS") %>%
  readRDS() %>% 
  list2env(envir = .GlobalEnv)

total_iterations <- (n_chains * (n_iterations - n_warmup) / n_thin)
```

The model is designed to estimate group-level parameters from an individual-level data generating process. As such, I begin by simulating individual-level item response data before aggregating the data to the group level for estimation. I simulate a universe containing `r n_states` states nested within `r english(n_regions)` regions, allocated so each region contains `r english(n_states / n_regions)` states. Each state contains `r english(n_districts)` districts containing voters belonging to `r english(n_parties)` parties, totaling `r n_states * n_districts * n_parties` groups across `r n_states * n_districts` districts in the whole "country." Data for each district-party group contain responses to `r n_items` items that are answered by `r n_cases` unique individuals apiece.^[
  While a single survey will not contain `r n_items` policy items, this study will pool items from several surveys into a final dataset.
]
 For simplicity, the simulation assumes that each individual answers only one question. When the model is implemented on real data, this assumption is relaxed by the weighting scheme laid out in Section&nbsp;\@ref(sec:model-weights).
  <!------- TO DO ---------
  - Fix
  ------------------------->

Individual partisans respond to each item probabilistically according to the individual-level item response model originally laid out in Equation&nbsp;\@ref(eq:y-i-probit). The probability $\pi$ that individual $i$ gives a conservative answer to item $j$ is
\begin{align*}
  y_{ij} &\sim \mathrm{Bernoulli}(\pi_{ij}) \\
  \pi_{ij} 
  &= 
  \Phi\left(\frac{\theta_{i} - \kappa_{j}}{\sigma_{j}}\right)
\end{align*} 
Once individual responses are simulated, the number of conservative responses are summed within each item-group and supplied to the model for estimation.

Simulating these individual level responses requires that we provide hyperparameter values to ideal points $\theta_{i}$, cutpoints $\kappa_{j}$, and dispersions $\sigma_{j}$. Beginning with the item parameters, every cutpoint value is drawn a Normal distribution with mean $0$ and standard deviation `r difficulty_sd`. Every dispersion parameter is defined as $\sigma_{j} = \iota_{j}^{-1}$, where $\iota_{j}$ is a LogNormal draw with mean $0$ and standard deviation `r discrimination_sd` on the log scale.

Individual ideal point parameters are Normal draws within their respective district-party groups ($\theta_{i} \sim \mathrm{Normal}\left(\bar{\theta}_{g[i]}, \sigma_{g[i]}\right)$), where each group has a potentially unique mean and standard deviation. As described in Section&nbsp;\@ref(sec:geographic-model), group means are generated from hierarchical models with parameters that vary across parties. I also specify a group-level regression to generate heteroskedasticity in $\sigma_{g}$, which the model does not currently estimate.
<!------- TO DO ---------
- fix this bit oh boy
------------------------->
\begin{align}
  \theta_{g} &=
    \mu_{0p} + 
    \mathbf{x}^{\intercal}_{d}\beta_{p} + 
    \mathbf{z}^{\intercal}_{s}\gamma_{p} +
    \epsilon_{dp}^{\mathtt{district}} + 
    \epsilon_{sp}^{\mathtt{state}} + 
    \epsilon_{rp}^{\mathtt{region}} \\
  \log\left(\sigma_{g}\right) &=
    \delta_{0p} + 
    \mathbf{x}^{\intercal}_{d}\delta_{p} + 
    \mathbf{z}^{\intercal}_{s}\zeta_{p} +
    \nu_{dp}^{\mathtt{district}} + 
    \nu_{sp}^{\mathtt{state}} + 
    \nu_{rp}^{\mathtt{region}}
\end{align}
The hierarchical regression contains district data $\mathbf{x}$, consisting of two standard normal covariates, and state data $\mathbf{z}$, containing just one standard normal covariate. Subscripts index groups $g$, districts $d$, states $s$, and regions $r$.^[
  For simplicity, notation for the hierarchical structure is left implicit in these equations.
]
To generate group means $\theta_{g}$, the constants $\mu_{0p}$ are explicitly set for each party $p$: $\mu_{0, p=1} = `r const_d`$ and $\mu_{0, p=2} = `r const_r`$. This implies that, on average, party $1$ is liberal, and party $2$ is conservative. District coefficients $\beta_{p}$ and state coefficients $\gamma_{p}$ are all simulated as Normal draws with mean $0$ and standard deviation `r sd_beta_d`. The hierarchical model contains party-specific error terms (denoted as $\epsilon$) for districts ($\mathrm{sd} = `r resid_theta_d`$), states ($\mathrm{sd} = `r resid_theta_s`$), and regions ($\mathrm{sd} = `r resid_theta_r`$). The setup is similar for the generation of group-level dispersion terms $\sigma_{g}$. The constants $\delta_{0p}$ are set to `r const_sig` for both parties, coefficients for districts ($\delta_p$) and states ($\zeta_{p}$) are both Normal draws with mean $0$ and std.\ dev.\ $`r sd_beta_d_sig`$, and there are separate mean-$0$ error terms $\nu$ for districts ($\mathrm{sd}= `r resid_sigma_d`$), states ($\mathrm{sd}= `r resid_sigma_s`$), and regions ($\mathrm{sd}= `r resid_sigma_r`$).

It is important to note that many of the parameters in this simulation are not hand-selected but simulated from probability distributions. This is done to obscure the true values of these parameters, ensuring that prior distributions are specified without knowledge of true values. To stress-test the model, I intentionally simulate the true parameters from distributions with narrower dispersions than the priors.
<!------- TO DO ---------
- more specific
------------------------->

I estimate the model by generating `r comma(total_iterations)` samples for each parameter across `r comma(n_chains)` Markov chains, `r comma(n_iterations - n_warmup)` iterations per chain. I warm up each chain for an initial `r comma(n_warmup)` iterations before saving samples.

```{r read-true-thetas}
group_level <- readRDS(
  here("data", "mcmc", "dgirt", "test", "input", "group-level-data.RDS")
)
```

```{r tidy-conf-level}
# saving this to print it later in the text
conf_level <- 0.9
```

```{r tidy-stanfit}
tidy_stanfit <- tidy(stanfit, conf.int = TRUE, conf.level = conf_level)
```

```{r save-thetas}
thetas <- tidy_stanfit %>%
  filter(
    str_detect(term, "theta\\[") == TRUE, 
    str_detect(term, "idtheta") == FALSE
  ) %>%
  mutate(group = parse_number(term)) %>%
  left_join(group_level %>% select(group, theta_g, sigma_g, party)) %>% 
  print()

# make a square plot, save abs_value of "biggest" theta
axis_limit <- thetas %$% max(max(theta_g), max(estimate)) %>% ceiling() %>% abs()
```

```{r plot-theta-scatters, include = TRUE, fig.height = 4, fig.width = 5, out.width = "70%", fig.cap = "Testing the ideal point model with simulated data: estimated vs. true ideal points for district-party groups. Estimates are plotted with means and compatibility intervals. Ellipses are included to identify the parties and carry no statistical interpretation."}
ggplot(thetas) +
  aes(x = theta_g, y = estimate, color = as.factor(party)) +
  geom_mark_ellipse(
      expand = unit(3, "mm"),
      aes(label = str_glue("Party {party}"), fill = as.factor(party)
          , color = NA
      ),
      alpha = 0.2,
      label.family = font_fam,
      label.fontface = "plain"
    ) +
  geom_abline(color = "black") +
  geom_pointrange(
    aes(ymin = (conf.low), ymax = conf.high),
    fatten = 2
  ) +
  labs(
    y = as.character(str_glue(
      "Model Estimate\n({percent(conf_level, accuracy = 1)} intervals)"
    )),
    x = "True Ideal Point",
    color = "Party"
  ) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  theme(legend.position = "none") +
  coord_cartesian(
    xlim = c(-axis_limit, axis_limit),
    ylim = c(-axis_limit, axis_limit)
  ) +
  NULL
```

Figure&nbsp;\@ref(fig:plot-theta-scatters) compares each group's "true" ideal point to its estimated ideal point from the IRT model. We observe a strong relationship between the true and estimated values, indicating that the model does a good job recovering the ideal points. We do observe a little bit of shrinkage in the ideal point estimates; the most and least conservative ideal points fall closer to zero compared to the $45^{\circ}$ line. This is likely owed to partial pooling in the model---since the model knows that it receives an uncertain signal about the ideal point, the hierarchical prior hedges its bet toward th estimated distribution of ideal points. Another source of attenuation could be the fact that the data are generated from a heteroskedastic model, but the model does not generate that heteroskedasticity. Unmodeled sources of variation add dispersion to the data, pulling the response probability toward $0.5$, which will pull ideal point estimates toward $0$ and increase the item dispersion parameters. 

```{r extract-icc-draws}
n_draws <- 50

draws <- df_stanfit %>%
  spread_draws(cutpoint[item], dispersion[item], n = n_draws, seed = sim_seed) %>%
  print()

# beepr::beep(2)
icc_draws <- draws %>%
  group_by(item) %>%
  crossing(theta = seq(-axis_limit, axis_limit, .05)) %>%
  mutate(
    pp = plogis((theta - cutpoint) / dispersion)
  ) %>%
  print()
```


```{r read-ij-data}
ij_level <- readRDS(
  here("data", "mcmc", "dgirt", "test", "input", "ij-level-data.RDS")
)
```



<!-- ICCs -->
```{r, eval = FALSE}
# # Just testing ICCs from known params
# ij_level %>%
#   ggplot() +
#   aes(x = theta_i, y = pi_ij) +
#   geom_line() +
#   facet_wrap(~ as.factor(item))
```

```{r plot-sim-ICCs, include = TRUE, fig.height = 10, fig.width = 8, out.width = "100%", fig.cap = 'Testing the ideal point model on simulated data: item characteristic curves from estimated (yellow) and true (black) item parameters'}
icc_draws %>%
  ggplot() +
  aes(x = theta, y = pp) +
  geom_vline(xintercept = 0, color = "gray", size = 0.25) +
  geom_hline(yintercept = 0.5, color = "gray", size = 0.25) +
  geom_line(aes(group = .draw), color = primary, size = 0.2) +
  geom_line(
    data = ij_level, color = "black", size = 0.35,
    aes(x = theta_i, y = pi_ij)
  ) +
  facet_wrap(
    ~ item,
    labeller = as_labeller(function(x) str_glue("Item {x}")),
    ncol = 5
  ) +
  coord_cartesian(xlim = c(-1 * axis_limit, axis_limit), ylim = c(0, 1)) +
  scale_y_continuous(breaks = seq(0, 1, .5)) +
  labs(x = "Ideal Point", y = "Probability of Conservative Response")
```

Figure&nbsp;\@ref(fig:plot-sim-ICCs) shows item response functions for all items. True IRFs are plotted in black, with IRFs from `r n_draws` randomly selected posterior samples in yellow. For the most part, the model is able to recover the shape of each item response function extremely well. Items with more extreme midpoint and discrimination values are slightly attenuated, likely owing to priors that exert some pull against extreme estimates. 


```{r, eval = FALSE}
# ggsave("~/desktop/test.pdf", height = 10, width = 8, device = cairo_pdf); beepr::beep(2)
```

```{r}
df_stanfit %>%
  spread_draws(item_scales[dim], item_rho) %>% 
  gather(key = param, value = value, contains('item_')) %>%
  mutate(
    param = 
      case_when(
        dim == 1 & param == "item_scales" ~ "sd_cut",
        dim == 2 & param == "item_scales" ~ "sd_logdisc",
        TRUE ~ "item_rho"
      )
  ) %>%
  ggplot() +
  aes(x = value) +
  facet_grid(~ param, scales = "free_x") +
  geom_ribbon(
    data = tibble(
      x = seq(-1, 3, .05),
      dbeta = dbeta((x + 1) / 2, 2, 2) / 2,
      dhalfnorm = dnorm(x) * 2
    ) %>%
    crossing(param = c("item_rho", "sd_cut", "sd_logdisc")) %>%
    mutate(
      density = case_when(
        param == "item_rho" ~ dbeta,
        str_detect(param, "sd") & x > 0 ~ dhalfnorm
      ) 
    ) %>%
    filter(
      (x > 0 & param != "item_rho") |
      (x <= 1 & param == "item_rho")
    ),
    aes(ymax = density, ymin = 0, x = x),
    fill = primary_light, alpha = 0.5
  ) +
  geom_histogram(
    aes(y = ..density..), 
    bins = 100,
    fill = primary, color = NA
  )
```


```{r item-scatter-posterior}
df_stanfit %>%
  spread_draws(dispersion[item], cutpoint[item], n = 500) %>%
  ggplot() +
  aes(x = cutpoint, y = dispersion) +
  geom_mark_ellipse(
    expand = unit(3, "mm"),
    aes(fill = as.factor(item)
        # , fill = as.factor(party) , color = NA
    ),
    color = NA,
    alpha = 0.1,
    label.family = font_fam,
    label.fontface = "plain"
  ) +
  ggpointdensity::geom_pointdensity() +
  viridis::scale_fill_viridis(discrete = TRUE) +
  NULL

```


<!-- item parameters
covariate values
residual values -->



<!------- TO DO ---------
- still need to compare the hierarchical distributions
------------------------->

to do: still want to examine the values of the hierarchical parameter estimates, but that requires a big more surgery in the model results!



<!-- Distill the simulation stuff here 

- Static, homoskedastic
- Static and heteroskedastic
- Heteroskedastic and dynamic

-->



