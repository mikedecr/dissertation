# District-Party Ideology and Primary Election Outcomes {#ch:voting}


$\renewcommand{\ind}[0]{\perp \!\!\! \perp}$
$\renewcommand{\doop}[1]{\mathit{do}\left(#1\right)}$
$\renewcommand{\diff}[1]{\, \mathrm{d}#1}$
$\renewcommand{\E}[1]{\mathbb{E}\left[#1\right]}$
$\renewcommand{\p}[1]{p\left(#1\right)}$


```{r stopper, eval = FALSE, cache = FALSE, include = FALSE}
knitr::knit_exit()
```

```{r knitr-05-1-voting, include = FALSE, cache = FALSE}
source(here::here("assets-bookdown", "knitr-helpers.R"))
```

```{r}
library("here")
library("magrittr")
library("tidyverse")
library("broom")

library("ggdag")
library("ggtext")
library("latex2exp")
library("patchwork")
```

Intro:

- Now that we have district-party ideology, does it appear to matter for candidate choice? 
- are more progressive/conservative districts more likely to prefer more progressive/conservative candidates?
- challenging modeling problem: the IV doesn't vary across candidates in the same primary, it only varies across primaries.
- This means that we require an approach to modeling candidate choice that incorporates the interaction between district-party ideology and candidate positioning

Overview:

- confront modeling challenges using a conditional logit approach: can only identify differences in candidate utility across candidates
- this affects which causal claims we can support, since the model can't directly identify how district-party ideology affects candidate utility in isolation
- discuss the relationship between feasible causal estimands and flexible conditional logit modeling approach for recovering how the effect of candidate positioning is heterogeneous across districts

We find:

- frame research question _as asked in the statistics_
- Democratic primaries exhibit ideological voting: there is an ideological "sweet spot" where candidates should position themselves to maximize their win probability
- However, the location of this sweet spot does not vary greatly across districts, meaning that variation in district-party ideology
- Among Republicans, there is much weaker ideological voting.
  Candidate value is not strongly related to their ideological positioning at all, leaving little room for effects to vary by districts.



## Modeling Candidate Choice

<!-- begin w/ lit review -->

<!-- small n of points -->


```{r utility-data}
chooser_data <- 
  tibble(
    x = -2,
    utility = 0,
    math_label = "bar(theta)[g]",
    label = "District-Party\nIdeology"
  )

util_data <- tibble(
  cand = seq(-10, 10, .1),
  u_distance = cand - chooser_data$x,
  utility = -u_distance^2  
)
```

```{r utility-model}
ggplot(util_data) +
  aes(x = cand, y = utility) +
  geom_line(color = primary) +
  geom_hline(yintercept = 0) +
  geom_point(data = chooser_data, aes(x = x)) +
  geom_text(
    data = chooser_data, aes(x = x, label = math_label), parse =TRUE, vjust = 2
  ) +
  geom_text(
    data = chooser_data, aes(x = x, label = label), vjust = -0.5
  ) +
  annotate(
    geom = "text", label = "← Candidate position →",
    x = 10, y = 0,
    hjust = 1, vjust = 2
  ) +
  annotate(
    geom = "richtext", 
    label = glue::glue("<b style='color:{primary}'>Candidate value</b> decreases<br>when candidate is farther<br>from group ideal point"),
    x = 4, y = -60,
    hjust = 1,
    label.color = NA, fill = NA,
    family = font_fam
  ) +
  coord_cartesian(ylim = c(-100, 20)) +
  theme_mgd_dag() +
  labs(
    x = NULL, y = NULL,
    title = "Spatial Model of Candidate Choice"
  )
```



What role does ideology play when constituencies nominate a primary candidate?
Spatial voting models argue that primary candidates are more likely to win the nomination when they position their candidacies closer in ideological space to the median primary voter [@downs:1957:economic-theory; @aldrich:1983:downsian-parties].
This is an essential mechanism underlying the strategic positioning dilemma theory, which states that a candidate must strike a balance between the median partisan voter and the district median voter in order to win both the primary and the general election [@burden:2001:polarizing-primaries; @brady-han-pope:2007:out-of-step].
This intuition appears to hold in general elections for U.S. House: candidates who are too progressive or too conservative perform worse than candidates who are "just right" [@canes-wrone-et-al:2002:out-of-step; @simas:2013:house-proximity].
Figure \@ref(fig:utility-model) plots the key insight of these spatial voting models.
A candidate is most appealing to a constituency when the candidate position (represented on the left–right ideological continuum) matches the constituency's preferred ideological outcome. 
The candidate is less appealing, or provies less _value_ or _utility_, as their ideological distance from the constituency ideal point grows.
This utility loss accumulates regardless of whether the candidate is too progressive or too conservative.

```{r utility-model, include = TRUE, fig.scap = "Spatial proximity and candidate utility.", fig.cap = "A spatial voting model's description of candidate value (utility) as a function of candidate position and district-party ideology. Candidate value is maximized at the group ideal point $\\bar{\\theta}_{g}$ and decreases in either direction. The example in this plot assumes quadratic utility loss."}
```

One important shortcoming of existing primary elections research is the inability of empirical models to capture this "optimal positioning" in primaries.
Studies often measure the relationship between candidate "extremity" and their performance in primary elections—finding that more extreme candidates are more likely to win primary elections [@king-et-al:2016:twitter-primary] or that this effect is limited to extreme Republicans [@nielson-visalvanick:2017:primary-elections]—but extremity is allowed only a constant or monotonic effect on the candidate's primary performance [@hall-snyder:2015:ideology; @king-et-al:2016:twitter-primary; @nielson-visalvanick:2017:primary-elections].
Without the possibility of non-monotonicity in the extremity–victory relationship, these empirical models do not reflect their underlying theoretical models.
The other key drawback in existing research is that many studies try to understand the effects of primaries using data from incumbent candidates or general election candidates, which can introduce selection bias by observing only primaries winners instead of all primary candidates including primary losers [e.g. @ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning; @clinton:2006:constituent-representation; @brady-han-pope:2007:out-of-step; @hirano-et-al:2010:primary-polarization; @mcghee-et-al:2014:nomination-systems; @kujala:2020:primary-donors].
Without somehow accounting for the menu of candidates that a primary electorate can choose from, these studies cannot observe whether extreme candidates are actually preferred over less extreme candidates .
Studies that avoid this problem exist but are less common [@porter-treul:2020:primary-experience].
The study design below remedies both of these problems by modeling candidate choice in primary elections using a conditional logit likelihood and using basis-splines to model nonlinear effects of candidate ideology.

As reviewed in Chapter \@ref(ch:arg), there are several reasons to doubt that House primary voting predominantly follows a spatial voting model.
Fewer voters are likely to be aware of candidate positioning in contexts where the party label does not provide differentiating information between candidates [@norrander:1989:primary-voters].
Voters do respond to policy differences between candidates if they are aware of policy differences [@lelkes:2019:policy-over-party], but it is costly for primary voters to learn about the contrasting policy views of primary candidates.
Voters may also be strategic, preferring the candidate that they believe is most likely to win the general election even if that candidate isn't closest to their ideal point [@simas:2017:primary-electability].
Candidate traits like incumbency, an "outsider" reputation [@porter-treul:2020:primary-experience], early fundraising [@bonica:2020:lawyers-in-congress], gender [in Democratic races, see @thomsen:2020:ideology-gender], or other "valence" features [@nyhuis:2018:separate-valences] may bolster candidates' primary success.
Candidate ideology may serve a selection function even before the primary election itself if moderate candidates are deterred from entering the primary in the first place [@thomsen:2014:moderate-candidates].



### Causal and statistical identifiability

This project is interested in understanding district-party ideology and how it shapes primary elections.
An essential constraint of this chapter's analysis is that the "effect of district-party ideology on primary election outcomes" is not a convenient causal quantity to work with.
This is because district-party ideology is constant across all primary candidates who compete in a primary contest, therefore it has no direct effect on the probability that any one candidate wins. 
It can only have indirect effects that interact with other characteristics of the candidates. 
This section discusses these indirect effects, how they interact with the modeling constraints for primary election data, and how we define causal estimands under these constraints. 

Consider a primary race $r$ containing $n_{r} > 1$ primary candidates, each candidate indexed $i$.
Let $y_{r} = i$ signify that candidate $i$ wins race $r$, with the probability that $i$ wins $r$ given by $\psi_{ir}$.
Choice settings such as this, where one chooser must select among several alternatives in the choice set, is traditionally modeled using a conditional logit likelihood [@mcfadden:1973:conditional-logit].
Conditional logit has been employed to study candidate choice in U.S. primaries by @ansolabehere-et-al:2004:direct-primary-party-loyalty, @culbert:2015:strategic-voting-presidential-primaries, @simas:2017:primary-electability, and @porter-treul:2020:primary-experience.
Conditional logit supposes that the chooser (in this case, a district-party group) selects a candidate $i$ by comparing the utility they would receive from each candidate in the race $r$.
Suppose that this utility $\mu_{ir}$ contains a systematic component $u_{ir}$ and a random component $e_{ir}$.
\begin{align}
  \mu_{ir} &= u_{ir} + e_{ir}
(\#eq:utility-error)
\end{align}
The probability that $i$ is chosen is defined as the probability that $\mu_{ir}$ is greatest among all alternatives.
Because error term $e_{ir}$ is not known, this probability is calculated as a function of the systematic components that can be predicted, typically using the softmax function.
\begin{align}
\begin{split}
  p\left(y_{r} = i\right) &= \psi_{ir} \\
  \psi_{ir} &= \frac{\text{exp}\left(u_{ir}\right) }{\sum\limits_{i \in r}^{n_{r}}\text{exp}\left(u_{ir}\right)}  
\end{split}
(\#eq:softmax-probability)
\end{align}
which follows from an assumption that $e_{ir}$ is distributed Gumbel, as in logistic regression.
The distinguishing feature of conditional logit is that _chooser_ attributes, utility shocks that are specific to the chooser and thus common across all choices, do not have identifiable effects on the resulting choice.
This is because the chooser attribute introduces the same utility shock to every $u_{ir}$ term in Equation \@ref(eq:softmax-probability).^[
  This only holds when chooser attributes affect the choice utility _additively_.
  This project will relax this constraint to insert chooser features in the model.
]
As a result, researchers using conditional logit tend not to include chooser attributes at all in their model of the utility function.
They instead model the choice problem as a function of the alternatives only, holding the chooser attributes fixed.

In the case of primary elections, choosers are primary electorates, and district-party ideology is fixed for a given electorate.^[
  District-party groups are not perfectly synonymous with primary electorates, since some constituents who belong to the district-party do not vote in the primary, and some primary voters may not identify with the party. 
  While this conceptual gap could be explored in future research projects, this project tolerates the inconsistency because the most recent evidence on the representativeness of primary electorates finds that they resemble the demographic profile and policy attitudes of the district-party public [@sides-et-al:2018:primary-representativeness].
  This analysis contains more years of data and relies on fewer modeling assumptions than analyses that conclude that primary electorates are more polarized than district-parties. [@jacobson:2012:polarization-origins; @hill:2015:nominating-institution].
]
This means that district-party ideology, under the standard conditional logit approach, cannot _directly_ affect which candidate is nominated by holding all else fixed.
This tracks with the spatial model picture laid out in Figure \@ref(fig:utility-model): shifting the district-party ideal point $\bar{\theta}_{g}$ left or right does affect utility, but only because it changes the distance between $\bar{\theta}_{g}$ and the candidate location.
In other words, the interaction between district-party ideology and candidate location is key.
More generally, chooser-level features can be included in conditional logit models as long as there is a cross-level interaction with choice-level data for statistical identification [@fox-et-al:2012:random-coef-logit].
Building a statistical model that enables this interactivity is an important contribution of this research design.

This conditional logit model's identifiability constraint matters for causal inference as well, because it affects which causal quantities make sense in this context.
Consider the potential outcome $\mu_{ir}\left(\bar{\theta}_{g[r]}, \text{CF}_{ir}\right)$, the systematic utility that is a function of district-party ideology and the candidate's ideological position.
Imagine that we intervene on district-party ideology and measure the average utility effect^[
  For the current discussion, we consider the effect on utility instead of the effect on win probability.
  This is because win probability is complicated by the presence of other candidates, whereas utility is a straightforward function of chooser and choice features.
  It is important to understand the relationship between the causal model structure and the outcome scale because treatments can have different effects on different scales [@vanderweele:2009:interaction-modification].
] 
of setting $\bar{\theta}_{g} = \theta$ versus some other value $\theta'$, $\E{\mu_{ir}\left(\theta, \text{CF}_{ir}\right) - \mu_{ir}\left(\theta', \text{CF}_{ir}\right)}$.
This effect does exist for individual candidates: making the district-party more liberal or conservative would affect the primary electorate's candidate utility by increasing or decreasing the ideological distance between the district-party and the candidate.
But because multiple candidates can run in the same race, and the primary electorate has the same district-party ideology each time they consider a new candidate, the average causal effect of district-party ideology implicitly averaging all of the conditional effects for all candidates.
This isn't unusual in the abstract: any average causal effect is an average over potential heterogeneities.
But this is complicated by the fact that the conditional logit model does not naturally measure chooser-level effects (like district-party ideology), making it impractical to condition on other district-level characteristics to identify the average effect of district-party ideology on candidate choice.

It is much simpler, instead, to consider the average effect of candidate positioning on candidate utility.
This average effect is also an implicit average over all interactions with district-party ideology, but conditioning on candidate features that confound the effect of CF scores is much simpler with conditional logit, so causal identification of choice-level effects is more analytically straightforward as well.
The conditional average effect of CF scores on candidate utility would thus be 
$\E{\mu_{ir}\left(\theta, \text{CF} \right) - \mu_{ir}\left(\theta, \text{CF}'\right) \mid C_{ir} = c, r}$,
for a comparison of two values $\text{CF}$ and $\text{CF}'$, fixing the district-party ideology at $\theta$ and conditioning on other candidate-varying attributes $C_{ir} = c$ and the race $r$.^[
  Conditioning on the race, which defines the choice set, is inherent to conditional logit.
  Conditioning on the choice set is what makes undermines the identifiability chooser-level effects without cross-level interactions.
]

Because this project is focused on the added value of observing district-party ideology, we go one step further to model effect heterogeneity over district-party ideology explicitly, rather than be content to average over it implicitly.
I approach this from an effect modification perspective, meaning that heterogeneous effects do not reflect the causal effects of interventions on district-party ideology, but instead reflect causal effects of CF scores conditional on a given district-party ideology value.
Formally, we say that district-party ideology is an "indirect modifier" if the CF score effect ($\text{CF}$ versus $\text{CF}'$) varies across levels of district-party ideology ($\theta$ versus $\theta'$) [@vanderweele-robins:2007:effect-modification].
\begin{align}
  \E{\mu_{ir}\left(\text{CF}\right) - \mu_{ir}\left(\text{CF}'\right) \mid \bar{\theta}_{g} = \theta, C_{ir} = c, r} 
  &- 
  \E{\mu_{ir}\left(\text{CF}\right) - \mu_{ir}\left(\text{CF}'\right) \mid \bar{\theta}_{g} = \theta', C_{ir} = c, r}
  (\#eq:hte)
\end{align}
<!------- TO DO ---------
- or maybe we should just say the expectation is over i \in r?
instead of conditioning on R?
------------------------->


```{r choice-dag}
clogit_dag <- 
  dagify(
    Y ~ CF + C + U,
    CF ~ G + C,
    G ~ U,
    exposure = "G",
    outcome = "Y",
    coords = tribble(
      ~ name , ~ x , ~ y ,
      "C"    , 1   , 2   ,
      "CF"   , 1   , 1   ,
      "G"    , 0   ,  1,
      "U"    , 0   , 0  ,
      "Y"    , 2   , 1
    ),
    labels = c(
      "G" = "bar(theta)[g]",
      "CF" = "CF[ir]",
      "C" = "C[ir]",
      "Y" = "mu[ir]",
      "U" = "U"
    )
  ) %>%
  tidy_dagitty() %>%
  print()
```

```{r plot-choice-dag}
ggplot(clogit_dag) +
  aes(x = x, y = y, xend = xend, yend = yend) + 
  geom_dag_edges(data_directed = filter(clogit_dag, name != "U")) +
  geom_dag_edges(
    data_directed = clogit_dag %>%
      filter((name == "U" & to == "G")),
    edge_color = "gray",
    edge_linetype = 2
  ) + 
  geom_dag_edges_arc(
    data = clogit_dag %>% filter(to == "Y" & name == "U"),
    curvature = -0.3,
    edge_linetype = 2, 
    edge_color = "gray"
  ) + 
  geom_dag_point(
    data = filter(clogit_dag, name != "U"),
    color = "gray80"
  ) + 
  geom_dag_node(
    data = filter(clogit_dag, name == "U"),
    internal_color = "gray",
    color = "white"
  ) + 
  geom_dag_text(
    aes(label = label), 
    parse = TRUE, 
    color = "black", 
    family = font_fam 
  ) + 
  theme_mgd_dag() + 
  theme(legend.position = "none") + 
  labs(
    x = NULL, y = NULL, 
    title = "How CF Score Affects Primary Victory",
    subtitle = "Indirect modification by district-party ideology"
  ) + 
  NULL
```

Figure \@ref(fig:plot-choice-dag) plots a causal graph of the system under consideration.
The causal effect of candidate position $\text{CF}_{ir}$ on candidate utility $\mu_{ir}$ is unidentified without conditioning on pre-treatment candidate features $C_{ir}$.
District-party ideology is included as an indirect modifier of the CF score effect $\text{CF}_{ir} \rightarrow \mu_{ir}$, represented with the path $\bar{\theta}_{g} \rightarrow \text{CF}_{ir}$ and no direct path between $\bar{\theta}_{g}$ and $\mu_{ir}$ [@vanderweele-robins:2007:effect-modification].
<!------- TO DO ---------
- could add labels to describe the U path, modification, etc.
------------------------->
Because district-party ideology is included as an indirect modifier instead of as a joint treatment, back-door paths that connect district-party ideology and candidate utility through unobserved variables $U$ are allowed to exist without confounding the CF score effect or the effect modification interpretation [@vanderweele:2009:interaction-modification].
They do confound the causal effects of district-party ideology, however, which is why the effect heterogeneity across districts has no causal interpretation.


```{r plot-choice-dag, include = TRUE, out.width = "60%",  fig.height = 6, fig.width = 6, fig.scap = "Causal Diagram of CF score effect on win probability.", fig.cap = "Causal Diagram of CF score effect on win probability. District-party ideology is an indirect modifier because has no direct effect on primary outcomes except through candidate proximity. Post-treatment candidate features $P_{i}$ and unobservables $U$ are uncontrolled but do not compromise identification."}
```









### Causal heterogeneity through continuous interaction

This section describes a statistical model for primary candidate choice that achieves two key objectives.
First, the model is designed to capture the heterogeneous causal effect of candidate positioning, conditional on district-party ideology.
That is, the model contains appropriate interactions to include chooser-level attributes in the model of choice.
And second, the model contains the flexibility to capture non-monotonic effects of candidate positioning: utility losses for candidates that position themselves too far from the district-party ideal point.
The model detailed below achieves these objectives using two tactics. 
The first tactic: I model candidate utility using a linear combination of CF scores and district-party ideology.
This linear combination projects CF scores and district-party ideology into a shared space that can be interpreted like a "distance" metric, allowing candidate utility to increase or decrease as a function of the distance metric.
The second tactic: The distance metric's effect on candidate utility is modeled with a spline function.
The spline function serves the dual purpose of capturing nonlinearities in candidate utility—an essential component of the spatial voting model—and preserving the interaction between chooser and choice data through those nonlinearities.
This strategy enables the effect of candidate positioning on candidate choice to be heterogeneous across candidates with different CF scores and heterogeneous across districts with different district-party ideology values.

The conditional logit model begins modeling the probability that candidate $i$ is chosen in race $r$ as a softmax function of $u_{ir}$, the systematic component of a candidate's utility conditional on the choice set.
\begin{align}
\begin{split}
  p\left(y_{r} = i\right) &= \psi_{ir} \\
  \psi_{ir} &= \frac{\text{exp}\left(u_{ir}\right) }{\sum\limits_{i \in r}^{n_{r}}\text{exp}\left(u_{ir}\right)} \\
  u_{ir} &= f\left(\text{CF}_{ir}, \bar{\theta}_{g[r]}\right) + \mathbf{c}_{ir}^{\intercal}\gamma
\end{split}
(\#eq:clogit-likelihood)
\end{align}
The systematic utility $u_{ir}$ is given a vague definition for the time being.
I use $f()$ to represent a flexible function of candidate $i$'s CF score and the district-party public ideology for group $g$ in which race $r$ is held.
I include a vector of candidate-level variables $\mathbf{c}_{ir}$ and regression coefficients $\gamma$.
Causal inference requires the assumption that conditioning on candidate features renders CF scores ignorable among the candidates in $r$. 

I then construct $f()$ as a flexible spline function of CF scores and district-party ideal points.
Although CF scores and district-party ideology both represent ideal point measures, the two measures are not constructed in the same ideal point space.
The first step for constructing the spline is to create a function that effectively maps these two measures into a common space.
Let $\Delta_{ir}$ be a linear combination of $\text{CF}_{ir}$ and $\bar{\theta}_{g}$,
\begin{align}
\begin{split} 
  \Delta_{ir} &= \alpha \text{CF}_{ir} + \beta\bar{\theta}_{g[r]} \\
  \alpha^{2} + \beta^{2} &= 1
\end{split}
(\#eq:linear-combo)
\end{align}
The linear combination represents an assumption that CF score space and district-party ideology space are linear transformations of one another, similar to the way Aldrich–McKelvey scaling estimates linear mappings between ideology spaces [@aldrich-mckelvey:1977:scaling; @hare-et-al:2015:bayes-aldrich-mckelvey].
The second line of \@ref(eq:linear-combo) restricts the coefficients to have a norm of $1$. 
This places an identifiability restriction on the location and scale of the $\Delta$ space.
Furthermore it implies a mapping between $\text{CF}$ space and $\bar{\theta}_{g}$ space, since $\beta$ is defined in terms of $\alpha$,
\begin{align}
\begin{split}
  1 &= \alpha^{2} + \beta^{2} \\
  \beta &= \pm\sqrt{(1 - \alpha^{2})}
\end{split}
\end{align}
which clarifies how the linear transformation is estimating essentially a scale factor between the two ideal point spaces.^[
  Restricting the value of $\beta > 0$ would identify the rotation of the $\Delta$ space as well.
  Such a restriction would improve the interpretability of the $\Delta$ space, but it would hinder Bayesian estimation by introducing unnecessary discontinuities in the posterior distribution.
]
The linear transformation gives $\Delta_{ir}$ the algebraic interpretation of a distance measure between the candidate's CF score and the district-party public ideology in the $\Delta$ space.

I then use $\Delta_{ir}$ to construct a set of basis functions, using a degree-$3$ polynomial basis with $30$ knots across the range of $\Delta_{ir}$.^[
  The symmetry of the $\Delta$ space is ensured by centering CF scores and district-party ideology so that their respective minima and maxima are equidistant from zero.
  This requires re-calculating $\Delta$ in each model, as CF scores and district-party ideology have different ranges for Republicans and Democrats.
]
Let $b_{k}(\Delta_{ir})$ be the $k$^th^ basis function out of $K$ total, each with a coefficient $\phi_{k}$.
The function $f()$ from \@ref(eq:clogit-likelihood) results then in a spline regression on $\Delta_{ir}$.
\begin{align}
\begin{split}
  u_{ir} &= f\left(\text{CF}_{ir}, \bar{\theta}_{g[r]}\right) + \mathbf{c}_{ir}^{\intercal}\gamma \\
  f\left(\text{CF}_{ir}, \bar{\theta}_{g[r]}\right) %_
    &= \sum\limits_{k} b_{k}\left(\Delta_{ir}\right)\phi_{k}
\end{split}
(\#eq:spline-function)
\end{align}

The spline regression enables a continuous interaction effect between CF scores and district-party ideology.
Because the basis functions are a nonlinear function district-party ideology, the derivative of $u_{ir}$ with respect to CF scores (the instantaneous effect of CF scores) is a function that contains district-party ideology $\bar{\theta}_{g}$.
By specifying the interacting between chooser- and choice-level data in this way, I sidestep the identifiability limitation of a simpler conditional logit model, allowing the causal effect of CF score to vary in different districts with different district-party ideologies. 
Interacting two continuous variables through the spline function is much more flexible than a multiplicative interaction between CF scores and district-party ideology, which would fail to capture both the utility optimum predicted by spatial voting models as well as any other non-constant interactions.
The intuition of the linear combination is also superior to the multiplicative interaction, since the notion of a common ideal point metric is a more faithful operationalization of the underlying spatial model.
The multiplicative interaction has no comparable interpretation.

Although the interpretation of $\Delta$ as a common ideal point metric is algebraically sensible, a limitation of the approach is that the model does not effectively identify which $\alpha$ and $\beta$ values create more plausible common spaces in terms of posterior probability.
This is because the spline regression is flexible enough to create sensible regression functions out of the multitude of possible $\Delta$ spaces.
In other words, if a particular draw of $\alpha$ and $\beta$ values "compress" the ideal point space in some way, the spline coefficients are able to "stretch" that space back out. 
As a result, the distribution of spline regressions is well identified from the data even if its component parameters—$\alpha$, $\beta$, and spline weights $\phi_{k}$—are not strongly identifiable on their own.
Stated differently, this model sacrifices some interpretability in order to fit a more flexible regression function, but this trade is worth it in order to capture nonlinear patterns in spatial voting while avoiding specific utility functions or ideal point mappings.




### Data

The data for this analysis are drawn primarily from two secondary sources, the Database on Interests, Money in Politics, and Elections [DIME, @bonica:2019:dime] and the Primary Timing Project [PTP, @boatright-et-al:2017:primary-timing-data]. 
Cases are organized at the candidate-contest level, with identifiers for each primary contest indexing political party $\times$ congressional district $\times$ election cycle.
Because primary candidates can run unopposed, I restrict the data to primary races containing at least two candidates.
I keep only primary races where the number of winning candidates equals $1$, which removes any election where the winner lacked a CF score estimate or where primary outcomes are miscoded in the original data sources.
I also drop any primary race where the outcome was decided by a convention instead of an election, and I drop all blanket and top-two primaries since those races are not limited to a single party.
<!------- TO DO ---------
- how many?
------------------------->

The DIME database contains most of the essential data used for this analysis: CF scores and primary outcome indicators.
Primary outcomes for the 2016 election cycle were less thoroughly coded than the primaries for 2012 and 2014, which led to lots of missing data.
Missing primary outcomes in the DIME were supplemented with data from the PTP.
Because candidate identifiers were not easily reconcilable using candidate identifiers,^[
  Candidate IDs in the DIME are regenerated with each vintage of the database, creating over-time inconsistencies candidate identifiers.
  As a result, the DIME identifiers in PTP do not match the identifiers in more recent DIME vintages.
]
I merge the databases using the probabilistic record-linkage algorithm developed by @enamorado-et-al:2018:record-linkage, linking candidates by name, state, district number, election cycle, and political party.
In cases where the DIME and the PTP disagree about primary outcomes, I defer to the PTP because its narrower substantive focus on primary elections lends it more credibility.
<!------- TO DO ---------
- ???
------------------------->

Predictive data include dynamic CF scores for every candidate and district-party ideal points from the IRT model in Chapter \@ref(ch:model).
The conditional logit does not identify district-level shocks to candidate utility because these variables are fixed for all candidates in a primary race, so the choice of controls in $\mathbf{c}_{ir}$ differs sharply from the district Chapter \@ref(ch:positioning).
Instead of including district-level demographics, economic indicators, or political background characteristics, $\mathbf{c}_{ir}$ contains candidate-level features that could affect their ideological positioning as well their likelihood of winning the primary.
I include an indicator variable for female candidate, which is associated with greater progressivism and a slightly higher primary win probability at least among Democrats [@thomsen-swers:2017:women-run; @thomsen:2019:women-win; @thomsen:2020:ideology-gender].
I also include an indicator for incumbent candidates, who both have more moderate CF scores (seen in Chapter \@ref(ch:positioning)) and are more likely to win their primary reelections.
I include no additional indicators for challengers and open-seat candidates, since open-seat races only compare open-seat candidates to one another, and non-incumbency implies challenger status for any race containing an incumbent candidate.
The standard control specification includes one last covariate for contribution amount that a candidate gives to themselves, which is logged and then standardized.
This control is intended to block a back-door path from CF scores to primary victory through candidate wealth, which could affect both the candidate's ideological position and their win probability.

Although there are additional measures of a candidate's campaign fundraising and spending available in the DIME, I do not use these variables as controls to identify the CF score effect.
This is because previous research theorizes that candidate ideology is more likely to influence a candidate's fundraising than vice-versa [@stone-simas:2010:candidate-valence; @barber-et-al:2016:ideological-donors; @thomsen-swers:2017:women-run].
The utility model underlying CF scores assumes that this is true _ex ante_, by modeling campaign contributions as a function of ideological affinity.
Using the same data for measurement and inference is presents problems that political scientists have been aware of, but political scientists are only just beginning to employ modern causal inference approaches to confront these problems [for an application to text analysis, see @egami-et-al:2018:causal-inf-texts].

I estimate separate models for Republicans and Democrats because control variables may confound the treatment effect differently for each party.
For instance, gender is thought to have a greater impact in Democratic primaries than in Republican primaries [@thomsen-swers:2017:women-run; @thomsen:2019:women-win; @thomsen:2020:ideology-gender].
It also may be the case that causal effects vary across party, either because Republicans or Democrats are not equally aware of political ideology or because district-party ideology has different modifying effects for Republicans and Democrats.
I also estimate the same model with the sample limited to primary contests with no incumbent present, a practice employed by earlier researchers to sidestep the overwhelming likelihood that incumbents win reelection [e.g. @porter-treul:2020:primary-experience].
<!------- TO DO ---------
- how many?
------------------------->


### Bayesian modeling, priors, and prior simulation

Like other models featured in this project, the Bayesian setup of this model provides several important benefits.
The most important benefit is regularization in the spline function.
Although the spline function is beneficial because it can fit many complex functions, complex models always run a risk of overfitting.
The trade-off between flexibility and overfitting is especially salient for modeling heterogeneous treatment effects because growing the number of possible comparisons will also grow the number of false positives if no additional methodological adjustments are made.
This concern has led researchers to use regularized estimators to detect heterogeneous effects, which introduce bias to shrink heterogeneities toward zero [for example with Bayesian regression trees, @hill:2011:bart; @green-kern:2012:bart].

```{r spline-coef-prior}
plot_spline_coef_draws <- tibble(
  raw = rnorm(10000),
  sigma = abs(rcauchy(10000, scale = 1)),
  phi = raw*sigma,
) %>%
ggplot() +
  aes(x = phi) +
  geom_histogram(
    boundary = 0, bins = 100, fill = primary
  ) +
  xlim(c(-10, 10)) +
  labs(
    x = TeX("Spline coefficient $\\phi_{k}$"),
    y = "Count",
    title = "Prior for Spline Coefficient",
    subtitle = "Normal prior with Cauchy scale"
  )
```



```{r spline-prior}
# possible spline functions
n_coef_draws <- 10
num_knots <- 30
spline_degree <- 3

coef_draws <- 
  tibble(
    k = 1:(num_knots + spline_degree)
  ) %>%
  crossing(
    rep = 1:n_coef_draws
  ) %>%
  mutate(
    sigma = rcauchy(n(), scale = 1) %>% abs(),
    phi_raw = rnorm(n()),
    phi = phi_raw * sigma
  ) %>%
  select(rep, k, phi) %>%
  pivot_wider(
    names_from = "rep",
    values_from = "phi",
  ) %>%
  select(-k) %>%
  print()

spline_data <- tibble(delta = seq(0, 1, length.out = 1000))
spline_data <- spline_data %$%
  splines::bs(
    delta,
    df = num_knots + spline_degree,
    degree = spline_degree, 
    intercept = TRUE 
  ) %>%
  (function(x) x %*% as.matrix(coef_draws)) %>%
  as_tibble() %>%
  set_names(~ str_glue("f_{.}")) %>%
  bind_cols(spline_data, .) %>%
  pivot_longer(
    cols = starts_with("f_"), 
    names_to = "draw",
    values_to = "spline"
  ) %>% 
  print()

plot_prior_spline_functions <- 
  ggplot(spline_data) +
  aes(x = delta, y = spline) +
  geom_line(
    aes(group = draw), 
    color = primary
  ) +
  geom_hline(yintercept = 0) +
  coord_cartesian(ylim = c(-8, 8)) +
  labs(
    x = TeX("$\\Delta_{ir}$: Linear combination of CF score and $\\bar{\\theta}_{g}$"),
    y = "Spline function",
    title = "Prior Draws of Spline Function",
    subtitle = str_glue("Prior simulations from {n_coef_draws} draws")
  ) +
  scale_x_continuous(breaks = c(0, 1), labels = c("Min", "Max")) +
  scale_y_continuous(breaks = seq(-6, 6, 3))
```


```{r plot-spline-priors}
plot_spline_coef_draws + plot_prior_spline_functions
```


I use a hierarchical prior for the spline coefficients to penalize the complexity of the resulting spline function.
The prior for each basis function's coefficient $\phi_{k}$ has a Normal distribution,
\begin{align}
  \phi_{k} &\sim \text{Normal}\left(0, \sigma \right)
  (\#eq:spline-marginal)
\end{align}
where $\sigma$ is another estimated parameter.
By estimating an adaptive prior distribution for the spline coefficients, coefficients are shrunk toward zero through partial pooling.
This prior is implemented in Stan as using a non-centered parameterization, which decomposes $\phi_{k}$ into a standard Normal variable $\tilde{\phi}_{k}$ and a scale factor $\sigma$.
\begin{align}
\begin{split}
  \phi_{k} &= \tilde{\phi}_{k}\sigma \\ %_ 
  \tilde{\phi}_{k} &\sim \text{Normal}\left(0, 1\right) %_
\end{split}
(\#eq:spline-shrinkage)
\end{align}
The non-centered parameterization stretches a standard Normal distribution in order to create a Normal distribution with a scale of $\sigma$.
This parameterization is valuable for Bayesian estimation because it de-correlates random variables in the posterior distribution, creating an easier posterior geometry for MCMC transitions.
I give the scale factor $\sigma$ a half-Cauchy prior,
\begin{align}
  \sigma &\sim \text{Half-Cauchy}\left(0, 1\right)
  (\#eq:scale-cauchy)
\end{align}
which regularizes the scale value toward zero but has a flatter tail to allow strong signals from the data to depart from the prior.
This Normal-Cauchy mixture is similar to the "horseshoe prior" and its variants [@carvalho-et-al:2010:horseshoe-prior; @piironen-vehtari:2017:horseshoe-hyperprior; @piironen-vehtari:2017:horseshoe-sparse-vs-reg], which is a popular prior for estimating sparse coefficients with regularization.^[
  Note that "sparsity" in this context does not imply coefficients of exactly-zero as it does with non-Bayesian L1 regularization [@tibshirani:1996:lasso; @ratkovic-tingley:2017:sparse-lasso-plus].
  Sparse priors may result in posterior _modes_ at zero, but posterior intervals will contain non-zero values [@park-casella:2008:bayesian-lasso].
]
The left-side panel in Figure \@ref(fig:plot-spline-priors) plots a histogram of simulated draws from this prior, which features a spike near zero and characteristically long Cauchy tails.^[
  The tails are long enough that many draws actually fall far outside the region plotted in the figure.
  These values are much rarer than the values contained in the plotted region, but they are much more probable than they would be under, for example, a Normal-Normal prior.
]


<!------- TO DO ---------
- plot a prior of the spline function???
- without a prior, this can oscillates to \pm infinity
- order-4 (3 degree) basis splines, 30 knots, N-C(0, 1) prior on 30 coefs
------------------------->

```{r plot-spline-priors, include = TRUE, fig.width = 9, fig.height = 5, out.width = "100%", fig.scap = "Prior draws of spline coefficient and spline function.", fig.cap = "Prior draws of spline coefficient and spline function. Left: histogram of prior draws for an individual spline coefficient. Right: draws from the implied prior over spline functions."}
```

The right panel of Figure \@ref(fig:spline-coef-prior) shows `r n_coef_draws` prior predictive draws of the spline functions, resulting from `r n_coef_draws` coefficient vectors drawn from the hierarchical prior.
There are a few important details to note about the construction of this prior.
First, most of the "peaks" of the spline function are in a neighborhood near zero, especially within the $(-3, 3)$ interval.
Although at first this sounds like a very narrow prior, it is important to remember that the spline function is defined on the utility (logit) scale, where small changes in utility can have large and nonlinear effects.
For context, a coefficient of $3$ on the logit scale would increase the success probability from $.5$ to `r plogis(3) %>% round(2)` in a two-candidate choice set, which is a larger effect than almost anything that occurs regularly in elections.
Furthermore, a preference for a spline functions near zero is essential for regularization, so this amount of prior information is appropriate for controlling the spline fit.
At the same time, there are several peaks that decisively escape the $(-3, 3)$ neighborhood.
These larger peaks reflect the flat that the Cauchy prior on $\sigma$ has thicker tails that allow larger values to occur more frequently.
The shape of the Cauchy tail retains enough flexibility to detect a spike in utility even if the center of the prior concentrates spline functions near zero.

For the remaining coefficients $\gamma$, I specify a weakly informative prior,
\begin{align}
  \gamma &\sim \text{Normal}\left(0, 5\right)
  (\#eq:clogit-wt-priors)
\end{align}
which rules out explosive coefficient values while still allowing candidate attributes like incumbency to exhibit large correlations with candidate utility.
For causal inference, it is important not to regularize confounding effects too much to avoid re-introducing bias into treatment effect estimates [@hahn-et-al:2018:regularization-confounding; @hahn-et-al:2020:bayesian-causal-forests].



## Findings


```{r plot-spline-posterior}
```

The average effect of a change in CF score on candidate utility can't be summarized by a single coefficient because of the nonlinear, interactive form of the spline function $f\left(\text{CF}_{ir}, \bar{\theta}_{g}\right)$.
The causal effect must instead be calculated as the difference in function values at different CF score inputs. 
Let $\text{CUE}\left(\text{CF}, \text{CF}', \theta, c\right)$ be the conditional utility effect (CUE) of moving to $\text{CF}$ from a reference value $\text{CF}'$, which is defined as
\begin{align}
  \text{CUE}\left(\text{CF}, \text{CF}', \theta, c\right) &=
    \E{f\left(\text{CF}, \bar{\theta}_{g}\right) \mid 
       \bar{\theta}_{g} = \theta, C_{ir} = c} \\
       &\quad -
    \E{f\left(\text{CF}', \bar{\theta}_{g}\right) \mid 
       \bar{\theta}_{g} = \theta, C_{ir} = c}
  (\#eq:cate-utility)
\end{align}
given a fixed value of $\bar{\theta}_{g} = \theta$ and conditioning on covariates $C_{ir}$. 
The Bayesian approach provides a definition for the probability distribution for $\text{CUE}\left(\text{CF}, \text{CF}', \theta, c\right)$ as well, which marginalizes over model parameters:
\begin{align}
  \p{\text{CUE}\left(\text{CF}, \text{CF}', \theta, c\right)} &=
  \int \p{f\left(\text{CF}, \theta \right) - f\left(\text{CF}', \theta \right) \mid \theta, \alpha, \beta} \\
  &\qquad \times \p{\alpha, \beta, \boldsymbol{\phi}} \diff \alpha \diff \beta \diff \boldsymbol{\phi}
  (\#eq:prob-cate-utility)
\end{align}
The conditional average effect on candidate utility can be gleaned by simply contrasting the function values in Figure \@ref(fig:plot-spline-posterior) for two different CF score values.

The conditional logit is a linear model for latent candidate utility, but causal effects on candidate win probabilities can be derived from the model as well.
Two intervening factors affect how candidate utility becomes win probability.
First, win probability is a nonlinear function of candidate utility, so a utility shock can have different effects on win probability depending on the baseline utility value.
Second, a primary race can feature a variable number of candidates, so a utility shock can have a smaller effect on win probability if there are more candidates in the race.
Let $\text{CWE}\left(\text{CF}, \text{CF}', \theta, c, r\right)$ be the conditional _win_ effect (CWE) of moving to $\text{CF}$ from a reference value $\text{CF}'$ in race $r$.
The CWE is a function of the race $r$ because each race could have different numbers of candidates with different utilities.
The CWE is the expected difference in softmax functions of candidate utility between CF score values $CF$ and $CF'$.
\begin{align}
  \text{CWE}\left(\text{CF}, \text{CF}', \theta, c, r\right) &=
    \E{\text{softmax}\left(u_{ir}(CF\right) \mid \theta, c, r} \\
    &\quad - 
    \E{\text{softmax}\left(u_{ir}(CF'\right) \mid \theta, c, r}
  (\#eq:cate-pwin)
\end{align}
where $u_{ir}\left(CF_{ir}\right)$ represents a candidate utility.
In turn, the probability distribution is
\begin{align}
  \p{\text{CWE}\left(\text{CF}, \text{CF}', \theta, c, r\right)} &= 
    \int \p{\text{softmax}\left(u_{ir}(CF\right) - \text{softmax}\left(u_{ir}(CF'\right) \mid \theta, c, r} \\
    &\qquad \times \p{\alpha, \beta, \boldsymbol{\phi} \gamma} \diff \alpha \diff \beta \diff \boldsymbol{\phi} \gamma
  (\#eq:prob-cate-pwin)
\end{align}

```{r win-grid}
```


Figure \@ref(plot:win-grid) visualizes causal effects on win probability.
The figure contains four comparisons in four different types of races: races with two and three candidates with no incumbents, and races with two and three candidates where one of the competing candidates is an incumbent. 
The function plotted in each panel is the conditional win effect (vertical axis) of a candidate occupying a certain CF score (horizontal axis) compared to the average CF score in their party.


## Discussion

### Other nonparametric Bayes approaches for flexible causal inference

Matching under measurement error in the covariates: <https://amstat.tandfonline.com/doi/full/10.1080/01621459.2015.1122601?casa_token=an-4oMYQN1AAAAAA%3AcmZp5oIxAb5Hs2kkR53JgHrrSXOd1HrLYDwQiuXOw_BaJVWcgG7ADtFcSQrIUQ2qRJTT999k4D-n>

### Causal inference with latent variables and measurement models
