# How District-Party Ideology Affects Primary Candidate Positioning: A Bayesian De-Mediation Model {#ch:positioning}

$\renewcommand{\ind}[0]{\perp \!\!\! \perp}$
$\renewcommand{\doop}[1]{\mathit{do}\left(#1\right)}$
$\renewcommand{\diff}[1]{\, \mathrm{d}#1}$
$\renewcommand{\E}[1]{\mathbb{E}\left[#1\right]}$
$\renewcommand{\p}[1]{p\left(#1\right)}$


<!------- TO DO ---------
- what's the latent relationship between local ideology and primary rules?
- does this explain the weird findings by McGhee et al?
- take credit for the Bayesian setup:
    - multilevel setup has a number of advantages for statistical identifiability and estimation
    - priors on ideal points
------------------------->

```{r stopper, eval = FALSE, cache = FALSE, include = FALSE}
knitr::knit_exit()
```


```{r knitr-04-1-positioning, include = FALSE, cache = FALSE}
source(here::here("assets-bookdown", "knitr-helpers.R"))
```

<!-- might need to add math -->

```{r packages-04-positioning, cache = FALSE}
library("knitr")

library("here")
library("magrittr")
library("tidyverse")

library("scales")
library("patchwork")
library("ggdag")
library("latex2exp")

library("broom")
library("tidybayes")

theme_dag <- theme_dag(base_family = font_fam)
```


Do primary elections effectively transmit citizens' policy preferences into government? 
For this to be true, we should expect that the policy ideology with a partisan constituency to affect the ideological positioning of candidates who run for that party's nomination. 
This chapter explores the effect of district-party public ideology on the positioning of primary candidates running in that district.

It is important to distinguish the influence of the district-party public from the influence of the district overall.
Does a candidate like Senator Susan Collins have a reputation as a moderate Republican because of a close balance between the number of Republican and Democratic voters in Maine? 
Or is the Republican constituency in Maine relatively moderate compared to Republican constituencies in states that elect more conservative Republicans? Although past research has been interested in the threat of primary challenges as a cause of ideological divergence between partisan legislators [for example @boatright:2013:getting-primaried; @hill:2015:nominating-institution; @hirano-et-al:2010:primary-polarization; @mcghee-et-al:2014:nomination-systems], many of these studies lacked the capability to observe the preferences within local partisan groups as a concept distinct from aggregate partisanship or aggregate voting in the entire district.
This chapter uses my new measures of district-party ideology to investigate this question in ways that previous research projects could not.

The effect of district-party ideology on candidate positioning is a challenging causal inference problem.
We cannot directly compare the "explanatory power" of district-party ideology and district-level voting by measuring whether one is more strongly correlated with candidate ideal points than the other, nor can we simply control for aggregate voting to recover the "partial effect" of district-party ideology.
This is because aggregate policy ideology and aggregate voting are causally related: if a district contains a voter base with more conservative policy preferences, these policy preferences should influence aggregate voting behavior in the district as well as the positioning of candidates who try to respond to those policy preferences.
Simply controlling for district voting in a regression will likely introduce collider bias by conditioning on a post-treatment variable [@greenland-et-al:1999:dags-epidemiology; @montgomery-et-al:2018:colliders].

This chapter investigates the effect of district-party ideology on primary candidate positions using a sequential-$g$ analysis, a multistage modeling approach that estimates the direct effect of district-party ideology while fixing district-level voting, which mediates the effect of local ideology.
Substantively, I translate the primary candidate's strategic positioning dilemma into the language of causal graphs, highlighting how aggregate districting voting mediates a relationship between district-party ideology and candidate positioning.
Methodologically, I take the sequential-$g$ method as it appears in political science [@acharya-blackwell-sen:2016:direct-effects] and embed it in a Bayesian framework.
The Bayesian framework estimates all components of the structural model simultaneously, quantifying uncertainty in all model parameters in a single posterior distribution.
This includes measurement uncertainty in ideal point estimates from the IRT model in Chapter \@ref(ch:model), which is included as a prior distribution over ideal points.
The key payoff for the Bayesian structure, therefore, is a unified framework for conducting inference about treatment effects by marginalizing over other sources of uncertainty, be they design parameters or imprecise data.

<!------- TO DO ---------
- Findings
------------------------->




## Candidate Positioning and Voters' Policy Preferences

How do constituent preferences affect candidate positioning?
This project explores the implications of what @brady-han-pope:2007:out-of-step call the "strategic positioning dilemma" (SPD), striking a balance between moderate position-taking to appease the general election constituency and ideological positioning taking to appease the partisan primary election constituency.
Existing research contains plenty of studies that support the general theoretical intuition of the SPD theory, although I review some conflicts and ambiguities in detail in Chapter \@ref(ch:arg).
To briefly review, general election candidates are rewarded at the ballot box for taking more moderate campaign stances [@canes-wrone-et-al:2002:out-of-step; @hall:2015:extremists] and aligning themselves with local public opinion on specific issues [@fenno:1978:home-style; @canes-wrone-et-al:2011:issue-accountability; though see @fowler-hall:2016:convergence].
Nevertheless, no candidate makes it to the general election without first winning a primary nomination, where many scholars theorize that candidates benefit by taking more ideological positions that represent conventional views within the party.
This could be a within-party Downsian incentive: the median primary voter is a ideological partisan with off-median policy preferences, so candidates take more extreme positions to appeal to partisan constituency preferences
[@aldrich:1983:downsian-parties; @burden:2001:polarizing-primaries].
This is consistent with evidence from safe congressional districts, where candidates experience less general election threat and can more freely position their campaigns to target the primary electorate [@ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning].
Pressures for primary candidates to take non-median stances may come through mechanisms unrelated to bottom-up voter pressures, instead reflecting candidates' need to organize committed staff and volunteers for their campaigns [@mcclosky-et-al:1960:conventions; @layman-et-al:2010:activists-conflict-extension; @aldrich:2011:why-parties], seek campaign funds from policy-seeking contributors [@laraja-schaffner:2015:campaign-finance-polarization; @barber:2016:contributions-polarization; @barber-et-al:2016:ideological-donors], or garner support from policy-demanding groups that control access to connections and resources to support candidates [@cohen-et-al:2009:party-decides; @koger-et-al:2009-partisan-webs; @masket:2009:no-middle-ground].

As I explained in more detail in Chapter \@ref(ch:arg), the explicit evidence about the SPD from primary elections themselves is surprisingly weak.
This is mainly because most studies do not explicitly measure the ideological preferences of primary voters, instead using aggregate measures of voting that are not able to identify policy preferences [@kernell:2009:districts].
Furthermore, most aggregate-level measures of policy ideology do not differentiate between partisan constituencies in the same district [e.g. @tausanovitch-warshaw:2013:constituent-prefs], which is important for understanding how candidates respond to their specific primary constituency.
Without data that more closely resembles the theoretical story in question, studies that claim to demonstrate that candidates "handle the [strategic positioning] dilemma by positioning themselves closer to the primary electorate" rarely show anything of the sort [@brady-han-pope:2007:out-of-step, p. 79].
@brady-han-pope:2007:out-of-step show that among incumbent members of Congress, more liberal Democrats and more conservative Republicans attract fewer primary challenges and perform better in primary elections, but neither of these findings say anything specific lessons about how candidates are positioned relative to primary constituencies.
@hirano-et-al:2010:primary-polarization get closer to this project's contribution by creating a statewide measure of primary electorate ideology from exit poll questions on ideological self-placement.
They find that incumbent NOMINATE scores are more strongly related to general electorate ideological self-placement than primary electorate self-placement, a similar pattern as shown in Chapter \@ref(ch:arg), Figure \@ref(fig:plot-compare-measures). 
They further find no evidence that incumbent members of Congress do not have more extreme NOMINATE scores under greater threats of primary competition or higher primary turnout.
This finding conflicts partially with @clinton:2006:constituent-representation, who uses a large opinion survey of partisan voters in every congressional district to show that Republican members of Congress have NOMINATE scores that are more strongly related to the median Republican in their district, while Democrats' NOMINATE scores are more strongly related to the overall district median constituent.
The IRT measures of district-party ideology that I create in Chapter \@ref(ch:model) is a more direct measure of policy preferences than ideological self-placement scores or additive issue scores, which respectively tap a large amount of "symbolic" or identity-focused conceptions of political ideology or do not accord for differential measurement error across policy issues [@ellis-stimson:2012:symbolic-ideology; @treier-hillygus:2009:ideology].
My IRT ideal point scores, to my knowledge, are the first ideology scores for district-party groups to be applied to the study of congressional primaries.^[
  For IRT estimates of partisan constituencies and "ideological nationalization" at the U.S. state level, see @caughey-et-al:2018:ideological-nationalization.
]

Research on primary competition and candidate positioning is also held back by the availability of primary candidate data, which until recently was not available. 
Past studies of primary competition and polarization typically use ideology scores from legislative roll call votes, which include only incumbent members of congress or state legislators [@brady-han-pope:2007:out-of-step; @hirano-et-al:2010:primary-polarization; @mcghee-et-al:2014:nomination-systems], or they use surveys of general election candidates, which may include non-incumbent candidates for the general election but no candidates who ran in the primary and lost [@ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning]. 
Recent ideal point methods that use political financial contributions data have the capacity to scale a much broader universe of political actors, including candidates, political parties, PACS and interest groups, and donors [@bonica:2013:ideology-interests; @bonica:2014:mapping-ideology; @hall-snyder:2015:ideology].
Few notable studies have yet used these contribution-based scores to study primary candidates [@thomsen:2014:moderate-candidates; @rogowski-langella:2015:primary-systems; @ahler-citrin-lenz:2016:CA-open-primaries; @porter-treul:2020:primary-experience; @thomsen:2020:ideology-gender].

Even with better measures of district-party ideology and candidate positions, there are some reasons to suspect that district-party ideology does not have a straightforward effect on candidate extremism. 
@thomsen:2014:moderate-candidates finds that politicians are less likely to run for Congress (versus a state office) if their moderate stances make them a weaker "fit" for their party, measured as a greater distance between a candidate's CFscore and the average CFscore in their state-party.
This process could weaken the relationship between district-party ideology and candidate positioning because moderate candidates select themselves out of the campaign, even if they might appeal to district partisan voters.
@porter-treul:2020:primary-experience find that the number of primary candidates who lack prior elected experience is increasing over time.
Interestingly, they find no pattern between candidate experience and candidate extremism.
This non-relationship may indicate that the positioning of inexperienced candidates may be less related to district-party ideology, either because the candidates are not adept at perceiving local ideology, they do not have the resources to conduct or acquire surveys of their constituencies, or emphasize non-ideological appeals in their campaigns. 
Incumbents, in turn, may be more responsive to local ideology as a result of their political skills and survivorship bias—ill-fitting candidates don't become incumbents in the first place—although incumbents systematically misperceive public opinion as well [@broockman-skovron:2018:bias].


### Primary rules

More recent studies of primary candidates tend not to focus on the overall relationship between voters' policy ideology and candidate positions. 
Instead, there is an enduring interest in the way primary rules affect candidates' positioning incentives by altering the composition of the primary electorate.
Primary "rules" refer to regulations in state election law that control which voters can participate in primary elections and which inclusion criteria parties can define within those legal confines.
A state primary is "closed" if only registered members of a political party are allowed to vote in the party's primary election.
On the other side of the spectrum, an "open" primary allows any registered voter to cast a vote in any party's primary.
There are many more states whose primary rules fall between these two extremes, such as "semi-closed" systems that allow party-unaffiliated voters to choose which party primary they want to vote for, even if registered partisans must vote in the primary of their party registration [@mcghee-et-al:2014:nomination-systems].
Political scientists and political observers speculate that these rules shape candidates' positioning incentives by changing the composition of primary voters.
Closed primary elections, so the argument goes, are limited to registered party identifiers in a district, so candidates running in closed primaries must appeal to a more ideologically homogeneous primary electorate in order to win the nomination.
More open systems, especially "blanket" systems where candidates from all parties run on the same primary ballot to advance to the general election, encourage primary candidates to take more moderate stances to attract a more ideologically diverse primary coalition.
The general hypothesis, therefore, is that more restrictive primary rules exacerbate ideological polarization in congress and in state legislatures, and furthermore that polarization might be combated by moving primary elections to more open rules.

This "primary rules hypothesis" receives essentially zero support across several studies of U.S. elections.
@hill:2015:nominating-institution studies the relationship between primary rules and the ideological makeup of the primary electorate, asking if primary voters in states with more open primary rules are in fact more moderate on average than primary voters under closed primary rules.
Estimating an IRT ideal point model on individual CCES respondents in each congressional district and validated voter turnout data, Hill finds that primary voters are more ideologically consistent than general election voters in the same party, but primary voters are no more extreme in closed primary states than in open primary states.
Even if primary electorates are not affected by state primary rules, candidates may still suspect that primary rules matter and position themselves accordingly.
@rogowski-langella:2015:primary-systems study the relationship between primary rules and candidate positioning as measured with CFscores.
They find no systematic evidence that either congressional candidates or state legislative candidates are more extreme in closed primary states or more moderate in open primary states. 
@mcghee-et-al:2014:nomination-systems also study state legislators but using ideology scores that bridge the NOMINATE ideal point space to state legislative voting [@shor-mccarty:2011:mapping-state-legs], again finding no convincing evidence that primary systems matter for polarization in state legislatures.
Within-state studies of changes to primary rules over time find mixed and highly qualified results, focused primarily on California's change to a "top two" primary system.^[
  In a top-two system, candidates from all parties compete in a single primary for two spots on the general election ballot, which are awarded to the top two plurality winners in the primary.
]
@bullock-clinton:2011:CA-blanket-primary find that the shift to the top-two primary promoted the election of more moderate candidates in California in competitive districts, measured using the two-party presidential vote, but no effects in more lopsided districts.
Looking at the mechanisms underlying this, however, @hill:2015:nominating-institution, who finds no effect on the ideological composition of primary voters after California's reforms, and survey experiments by @ahler-citrin-lenz:2016:CA-open-primaries broadly show that voters are unable to identify which candidates are more ideological and which are more moderate.

I leverage my new data on district-party ideology to revisit the primary rules hypothesis in Section \@ref(sec:pos-rules) below.
Unlike most studies, I find that more candidates are less responsive to district-party ideology in states with more open primary rules, consistent with the primary rules hypothesis.
<!------- TO DO ---------
- come back
- discuss "effect modification" (kam-trussler) interpretation below.
------------------------->

### Ideology inside the two major parties

What to do we think we know about ideology and the parties, and how should it condition our expectations and interpretations of the evidence that we see here?

- Hopkins vs. Sniderman theory
- does party's issue emphasis mean parties should collapse, or that variation should track
- Grossman-Hopkins; parties care about issues so they try to position themselves on it
  + read their stuff to see how they quality this
  + do they think districts collapse?
- weighting issues: left groups see fine variation in left members, but republicans are all bunched at zero (Brunell? Linda Fowler?)
- or Sniderman conflicted theory: Democrats are conflicted about appeasing groups, so variation matters. Republicans are NOT conflicted because many rationales point to the same policy prescription
    - lelkes sniderman 2016: ideological asymmetry
- THINK about abortion as a toy case
  + if weighting... if not weighting...




### Exploratory analysis

The analysis begins by examining the topline correlation between district-party ideology and candidate positions.
For the dependent variable, I use the dynamic CF score included in the DIME congressional candidate database for 2012, 2014, and 2016 candidates [@bonica:2019:dime]. 
For district-party ideology, I use the mean from the MCMC samples of the IRT model in Chapter \@ref(ch:model), which are estimated from polling data over the 2010s districting cycle.
Using only the mean understates the amount of uncertainty in the ensuing analysis, which is later corrected in the full analysis.
For now, these initial investigations serve only to give us an impression of the raw data.

<!------- TO DO ---------
- - what is the relationship
- let's control for the thing
- what does this imply?
------------------------->




<!------- TO DO ---------
- causal inference...
- what isn't in the lit, what is, and what this project is doing
------------------------->


```{r read-data, eval = TRUE}
full_data <- read_rds(here("data", "_clean", "candidates-x-irt.rds"))
```

```{r by-party}
party_fits <- full_data %>%
  group_by(party_num) %>%
  nest() %>%
  mutate(
    correlation = map_dbl(
      .x = data,
      .f = ~ cor(
        .x$recipient_cfscore_dyn, 
        .x$theta_mean,
        use = "pairwise.complete.obs"
      )
    ),
    lmfit = map(
      .x = data,
      .f = ~ lm(recipient_cfscore_dyn ~ theta_mean, data = .x)
    ),
    lmtidy = map(.x = lmfit, .f = tidy, conf.int = TRUE),
    lmfit_std = map(
      .x = data, 
      .f = ~ {
        .x %>%
        select(recipient_cfscore_dyn, theta_mean) %>%
        na.omit() %>%
        mutate_at(
          .vars = vars(recipient_cfscore_dyn, theta_mean),
          .funs = ~ scale(.) %>% as.vector()
        ) %>%
        lm(recipient_cfscore_dyn ~ theta_mean, data = .) 
      }
    ),
    stidy = map(.x = lmfit_std, .f = tidy, conf.int = TRUE),
    lmglance = map(lmfit, glance)
  ) %>%
  print()

party_coefs <- party_fits %>% 
  unnest(lmtidy) %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$term)) %>%
  print()

party_coefs_std <- party_fits %>% 
  unnest(stidy) %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$term)) %>%
  print()

byparty_labels <- party_fits %>%
  unnest(lmglance) %>%
  mutate(
    n = df + df.residual,
    party = names(party_colors)[party_num]
  ) %>%
  select(party, n, correlation, p.value) %>%
  ungroup() %>%
  print()
```

```{r plot-by-party}
ggplot(full_data) +
  aes(x = theta_mean, y = recipient_cfscore_dyn) +
  geom_point(
    aes(color = as.factor(party_num)), 
    size = 2.5, shape = 16, alpha = 0.25
  ) + 
  geom_smooth(
    aes(group = as.factor(party_num)), 
    color = "black",
    method = "lm",
    size = 0.25
  ) +
  scale_y_continuous(breaks = seq(-4, 4, 2)) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  labs(
    title = "Primary Candidate Positioning and Group Ideology",
    subtitle = "Candidates from 2012, 2014, and 2016",
    x = "District-Party Ideal Point\n(Posterior Mean)", 
    y = "Candidate CF Score"
  ) +
  theme(legend.position = "none") +
  geom_text(
    data = byparty_labels %>%
      mutate(
        theta_mean = c(-1.75, 0.05),
        recipient_cfscore_dyn = c(3, -3)
      ),
    aes(label = str_glue("{party} (n = {comma(n)})\nr = {round(correlation, 2)}")),
    hjust = 0
  ) 
```

Figure \@ref(fig:plot-by-party) shows the topline relationship between primary candidate CF scores and the ideal point mean for the district-party they ran to represent.
The figure contains candidates from 2012, 2014, and 2016 congressional primaries, including incumbents, challengers, and open-seat candidates.
This totals `r byparty_labels %>% filter(party == "Democrats") %>% pull(n) %>% comma()` Democratic candidates and `r byparty_labels %>% filter(party == "Republicans") %>% pull(n) %>% comma()` Republican candidates over three election cycles.
The figure shows a weak but decisively positive relationship between ideal point means and CF scores; district-parties that are more conservative see more conservative primary candidates. 
The relationship is stronger for Democrats than for Republicans in slope (`r party_coefs[["1"]]$theta_mean$estimate %>% round(2)` versus `r party_coefs[["2"]]$theta_mean$estimate %>% round(2)`) and in correlation (`r party_coefs_std[["1"]]$theta_mean$estimate %>% round(2)` versus `r party_coefs_std[["2"]]$theta_mean$estimate %>% round(2)`).
Because one-unit increases are large on the ideal-point scale, it is convenient to interpret the correlation coefficients as standardized coefficients, where each party is standardized separately.
Increasing district-party ideology by one within-party standard deviation is associated with a CF scores increase `r party_coefs_std[["1"]]$theta_mean$estimate %>% round(2)` standard deviations among Democrats and `r party_coefs_std[["2"]]$theta_mean$estimate %>% round(2)` standard deviations among Republicans.
A small number of outlier CF scores exist for each party, but these outliers are few compared to the approximately 2,000 observations in each party.
The regression lines track the center of each party's ideal point distribution, so these outliers do not appear to be large influences on the topline relationship.


```{r plot-by-party, include = TRUE, fig.width = 7, fig.height = 5, fig.cap = "Topline relationship between district-party ideology and candidate positions. The horizontal axis plots the posterior mean for a group ideology, and the vertical axis is the dynamic CF score for primary candidates included in the DIME congressional candidate database.", fig.scap = "Topline relationship between district-party ideology and candidate positions."}
```


```{r by-incumbency}
incumbency_fits <- full_data %>%
  group_by(party_num, incumbency) %>%
  nest() %>%
  mutate(
    correlation = map_dbl(
      .x = data,
      .f = ~ cor(
        .x$recipient_cfscore_dyn, 
        .x$theta_mean,
        use = "pairwise.complete.obs"
      )
    ),
    lmfit = map(
      .x = data,
      .f = ~ lm(recipient_cfscore_dyn ~ theta_mean, data = .x)
    ),
    lmtidy = map(.x = lmfit, .f = tidy, conf.int = TRUE),
    lmfit_std = map(
      .x = data, 
      .f = ~ {
        .x %>%
        select(recipient_cfscore_dyn, theta_mean) %>%
        na.omit() %>%
        mutate_at(
          .vars = vars(recipient_cfscore_dyn, theta_mean),
          .funs = ~ scale(.) %>% as.vector()
        ) %>%
        lm(recipient_cfscore_dyn ~ theta_mean, data = .) 
      }
    ),
    stidy = map(.x = lmfit_std, .f = tidy, conf.int = TRUE),
    lmglance = map(lmfit, glance)
  ) %>%
  print()

incumbency_coefs <- incumbency_fits %>% 
  unnest(lmtidy) %>%
  filter(term == "theta_mean") %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$incumbency)) %>%
  print()

incumbency_coefs_std <- incumbency_fits %>% 
  unnest(stidy) %>%
  filter(term == "theta_mean") %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$incumbency)) %>%
  print()

incumbency_labels <- incumbency_fits %>%
  unnest(lmglance) %>%
  mutate(
    n = df + df.residual,
    party = names(party_colors)[party_num]
  ) %>%
  select(party, n, correlation, p.value) %>%
  ungroup() %>%
  arrange(
    party, 
    fct_relevel(str_glue("{incumbency}s"), "Incumbents", "Challengers")
  ) %>%
  print()
```



```{r plot-by-incumbency}
ggplot(full_data) +
  aes(x = theta_mean, y = recipient_cfscore_dyn) +
  facet_wrap(~ fct_relevel(str_glue("{incumbency}s"), "Incumbents", "Challengers")) +
  geom_point(
    aes(color = as.factor(party_num)), 
    size = 2.5, shape = 16, alpha = 0.25
  ) + 
  geom_smooth(
    aes(group = as.factor(party_num)), 
    color = "black",
    method = "lm",
    size = 0.25
  ) +
  scale_y_continuous(breaks = seq(-4, 4, 2)) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  labs(
    title = "Incumbency Status and Ideological Responsiveness",
    subtitle = "Candidates from 2012, 2014, and 2016",
    x = "District-Party Ideal Point\n(Posterior Mean)", 
    y = "Candidate CF Score"
  ) +
  theme(legend.position = "none") +
   geom_text(
     data = incumbency_labels %>%
       mutate(
         theta_mean = c(rep(-1.75, 3), rep(-0.25, 3)),
         recipient_cfscore_dyn = c(rep(3, 3), rep(-3, 3))
       ),
     aes(label = str_glue("{party}\nn = {comma(n, accuracy = 1)}\nr = {round(correlation, 2)}")),
     hjust = 0
   ) 
```

Figure \@ref(fig:plot-by-incumbency) plots the same relationship with candidates divided into incumbents, challengers of incumbents, and candidates running for a district with no incumbent running for reelection.
It is immediately noticeable that CFscores have lower variance among incumbent candidates than among non-incumbent incumbents, and the correlations between CF scores and ideal point means are markedly higher: `r incumbency_coefs_std[["1"]]$Incumbent$correlation %>% round(2)` among Democrats and `r incumbency_coefs_std[["2"]]$Incumbent$correlation %>% round(2)`.
The overall higher correlation suggests incumbents are either more capable at positioning themselves for their primary electorates or that elections screen out ill-fitting incumbents. 
The higher correlation among Democrats also disappears among incumbent candidates, suggesting that no party is obviously more responsive to primary constituencies than the other, contrary to @clinton:2006:constituent-representation's finding that Republican incumbents were uniquely sensitive to ideological variation within their partisan bases.
Although CF scores are higher variance among challengers and open-seat candidates, and their relationship to district-party ideology is weaker, we still observe a generally positive relationship that candidates of all status have some awareness, on average, of how to take more conservative or liberal positions in response to their local constituencies.

```{r plot-by-incumbency, include = TRUE, out.width = "100%", fig.width = 9, fig.height = 5, fig.cap = "District-party ideology and candidate positioning across candidate incumbency status.", fig.scap = "District-party ideology and candidate positioning for incumbents, challengers, and open-seat candidates."}
```

```{r by-cycle}
cycle_fits <- full_data %>%
  group_by(party_num, cycle) %>%
  nest() %>%
  mutate(
    correlation = map_dbl(
      .x = data,
      .f = ~ cor(
        .x$recipient_cfscore_dyn, 
        .x$theta_mean,
        use = "pairwise.complete.obs"
      )
    ),
    lmfit = map(
      .x = data,
      .f = ~ lm(recipient_cfscore_dyn ~ theta_mean, data = .x)
    ),
    lmtidy = map(.x = lmfit, .f = tidy, conf.int = TRUE),
    lmfit_std = map(
      .x = data, 
      .f = ~ {
        .x %>%
        select(recipient_cfscore_dyn, theta_mean) %>%
        na.omit() %>%
        mutate_at(
          .vars = vars(recipient_cfscore_dyn, theta_mean),
          .funs = ~ scale(.) %>% as.vector()
        ) %>%
        lm(recipient_cfscore_dyn ~ theta_mean, data = .) 
      }
    ),
    stidy = map(.x = lmfit_std, .f = tidy, conf.int = TRUE),
    lmglance = map(lmfit, glance)
  ) %>%
  print()

cycle_coefs <- cycle_fits %>% 
  unnest(lmtidy) %>%
  filter(term == "theta_mean") %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$cycle)) %>%
  print()

cycle_coefs_std <- cycle_fits %>% 
  unnest(stidy) %>%
  filter(term == "theta_mean") %>%
  split(.$party_num) %>%
  lapply(function(x) x %>% split(.$cycle)) %>%
  print()

cycle_labels <- cycle_fits %>%
  unnest(lmglance) %>%
  mutate(
    n = df + df.residual,
    party = names(party_colors)[party_num]
  ) %>%
  select(party, n, correlation, p.value) %>%
  ungroup() %>%
  arrange(party, cycle) %>%
  print()
```

```{r plot-by-cycle}
ggplot(full_data) +
  aes(x = theta_mean, y = recipient_cfscore_dyn) +
  facet_wrap(~ str_glue("{cycle} Campaign")) +
  geom_point(
    aes(color = as.factor(party_num)), 
    size = 2.5, shape = 16, alpha = 0.25
  ) + 
  geom_smooth(
    aes(group = as.factor(party_num)), 
    color = "black",
    method = "lm",
    size = 0.25
  ) +
  scale_y_continuous(breaks = seq(-4, 4, 2)) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  labs(
    title = "Ideological Responsiveness Across 2010s Districting Cycle",
    subtitle = "Each year contains incumbents, challengers, and open seats",
    x = "District-Party Ideal Point\n(Posterior Mean)", 
    y = "Candidate CF Score"
  ) +
  theme(legend.position = "none") +
  geom_text(
    data = cycle_labels %>% 
      mutate(
        theta_mean = c(rep(-1.75, 3), rep(-0.25, 3)), 
        recipient_cfscore_dyn = c(rep(3, 3), rep(-3, 3)) 
      ), 
    aes(label = str_glue("{party}\nn = {comma(n, accuracy = 1)}\nr = {round(correlation, 2)}")), 
    hjust = 0
  ) 
```


Finally, Figure \@ref(fig:plot-by-cycle) shows how the relationship between district-party ideology and CF scores varies by election year, splitting the 2012, 2014, and 2016 campaign cycles into three panels.
There is no definitive trend toward increasing polarization or increasing responsiveness to partisan ideology in more recent years, which which is inconsistent with notions that candidates have become more hyper-focused on primary electorates in the past few election cycles.
The same weak but positive relationship appears in all years.
The flattest relationship actually appears most recently for Republicans in 2016, among whom the relationship is relatively flat.
I hesitate to interpret too much out of a single observation, but future researchers might investigate whether financial contributions by Republican donors had a different ideological character in 2016, either because Donald Trump's unusual campaign platform altered which donors wanted to support which causes, or if moderate donors directed their money away from Republican candidates in anticipation of a Clinton presidential win. 

<!------- TO DO ---------
- why is this
------------------------->

```{r plot-by-cycle, include = TRUE, out.width = "100%", fig.width = 9, fig.height = 5, fig.cap = "District-party ideology and candidate positioning across election cycles within the 2010s districting cycle.", fig.scap = "District-party ideology and candidate positioning in 2012, 2014, and 2016."}
```




```{r simple-regs, eval = FALSE}
simple_regs <- 
  read_rds(here("data", "_model-output", "04-positioning", "simple-regs.rds"))
```



```{r plot-first-look, eval = FALSE}
full_data %>%
  filter(
    is.na(recipient_cfscore_dyn) == FALSE &
    is.na(theta_mean) == FALSE
  ) %>%
  ggplot() +
  aes(x = scale(theta_mean), y = recipient_cfscore_dyn) +
  facet_grid(
    str_glue("{cycle} Campaign") ~ fct_relevel(incumbency, "Incumbent")
  ) +
  # facet_wrap(
  #   ~ str_glue("{cycle} Campaign")
  # ) +
  geom_point(
    aes(color = as.factor(party)), 
    size = 1, shape = 1, alpha = 0.5
  ) + 
  geom_smooth(
    aes(fill = as.factor(party)), 
    color = "black",
    method = "lm",
    size = 0.25
  ) +
  scale_y_continuous(breaks = seq(-4, 4, 4)) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  labs(x = "District-Party Ideal Point", y = "Candidate Dime Score") +
  theme(panel.grid = element_line(color = "gray90")) +
  geom_text(
    data = tibble(
      theta_mean = c(-1.25, 0.25),
      recipient_cfscore_dyn = c(-3, 3),
      text = c("Democrats", "Republicans"),
      cycle = 2012, 
      incumbency = factor("Incumbent")
    ),
    aes(label = text)
  ) +
  # geom_label(
  #   data = simple_regs,
  #   aes(x = (party - 1.5), y = -5 * (party - 1.5), 
  #       label = str_glue("r = {number(sqrt(r.squared), accuracy = .01)}\nb = {number(estimate, accuracy = .01)}\nn = {df + df.residual}")),
  #   color = "black", size = 3
  # ) +
  theme(legend.position = "none")
```

With direct measures of district-party policy ideology, do we get a different topline picture of within-party representation in primaries? Figure&nbsp;\@ref(fig:plot-first-look) shows a descriptive picture of the relationship between district-party ideology and candidate ideology for House primary candidates, the latter measured with dynamic ideal point scores derived from campaign contributions [@bonica:2014:mapping-ideology]. Across incumbents, challengers, and open-seat candidates, in both parties, and across several election cycles, we observe a generally positive relationship between these two measures. As partisan citizens in a district become more conservative, so too do the candidates who run in those districts.


```{r plot-first-look, include = TRUE, fig.width = 8, fig.height = 6, eval = FALSE, out.width= "100%", fig.cap = "Simple comparison of candidate Dime scores against their respective district-party ideal points. Results generally indicate a positive relationship: as partisan constituents in a district hold more conservative policy preferences, candidates running for that party's nomination in the House are also more conservative."}
```


The strength of these relationships vary most dramatically by candidate incumbency status, which could be owed to competitive positioning incentives when, for example, challengers attempt to differentiate themselves ideologically from incumbents in ways that aren't entirely explained by bottom-up ideological pressure from voters [c.f. @ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning]. Incumbent candidates' ideal points are most strongly related to district-party ideology, consistent with a notion that ideological consistency creates a selection effect into incumbency in previous election. 

This descriptive picture informs a few modeling choices during the sequential-$g$ routine. Because incumbency status appears to be a substantial modifier of the relationship between citizen and candidate ideology, I estimate the direct effect of district-party ideology separately for incumbents, challengers, and open seat candidates. By comparison, estimates are quite similar across election cycles, so I pool election cycles into one model with cycle fixed effects rather than estimating entirely separate models for different cycles. And although the descriptive relationships vary modestly across parties, the variables that could confound the relationship between citizen and candidate ideology could differ dramatically across parties. I therefore estimate models for Democrats and Republicans separately. This results in six groups of sequential-$g$ estimates: three incumbency categories $\times$ two major parties.


<!------- TO DO ---------
- whom to attribute to?
------------------------->





<!------- TO DO ---------
- plot vote as f(theta)
------------------------->

```{r, eval = FALSE}
ggplot(dime) +
  aes(
    y = district_pres_vs, x = theta, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    y = "Past Republican Presidential Vote",
    x = "District-Party Ideology"
  ) +
  facet_wrap(~ cycle, ncol = 1) +
  # scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1))
  NULL
```

```{r plot-scattering, eval = FALSE}
(
  ggplot(dime) +
  aes(
    x = district_pres_vs, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "Dynamic Dime Score"
  ) +
  scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1))
) /
((
  ggplot(dime) +
  aes(
    x = district_pres_vs, y = dwnom1, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "DW-Nominate (D1)"
   ) +
   scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1)) +
   scale_y_continuous(limits = c(-1, 1))
) +
(
  ggplot(dime) +
  aes(
    x = dwnom1, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    y = "Dynamic Dime Score", 
    x = "DW-Nominate (D1)"
   ) +
   scale_x_continuous(limits = c(-1, 1))
))
```

Although this descriptive picture is suggestive about the relationship between district-party ideology and candidate ideology, we need more rigorous methods to interrogate a causal relationship. In particular, we should be concerned that district features that promote conservative voters also promote conservative candidates, so background features of districts are important to control. Furthermore, if it is worthwhile for researchers to consider the unique effect of district-party ideology, it is important to demonstrate that it affects candidate positioning above and beyond its intermediate effect on district voting. The sequential-$g$ approach confronts both of these threats to inference. 

<!-- Figure&nbsp;\@ref(fig:plot-scattering) shows... -->

```{r plot-scattering, include = FALSE, fig.width = 5, fig.height = 4, eval = FALSE, out.width= "70%", fig.cap = "Presidential Vote Shares and Ideal Point Measures, 2012--2016"}
```



```{r plot-scatter-by-incumbency, eval = FALSE}
ggplot(dime) +
  aes(
    x = district_pres_vs, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "Dynamic Dime Score"
  ) +
  scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1)) +
  facet_wrap(~ str_glue("{incumbency}s"))
```

<!-- put graph here -->
<!-- cces figure -->
<!-- dime vs. party prefs, dime vs. district voting -->
<!-- swap dime for DW-Nominate -->







### The direct effect of district-party ideology

Make the argument for the direct effect setup

- appeal to SPD theory
- connect to spatial theory: we don't get different voting _but for_ different voter distributions
- this may be unrealistic, but that is perhaps the point, since this is theory testing.


```{r problem-dag}
problem_dag <- 
  dagify(
    CF ~ I + V + U,
    V ~ I + U,
    exposure = "I",
    outcome = "CF",
    coords = tribble(
      ~ name,      ~ x,    ~ y,
      "I",       1,   1,
      "CF",       3,   1,
      "V",       2,   0,
      "U",      3,      0
    ),
    labels = c(
      "I" = "District-Party Ideology",
      "CF" = "Candidate Positioning",
      "V" = "District Voting"
    )
  ) %>%
  tidy_dagitty() %>%
  # node_parents("CF") %>%
  mutate(
    pt_label = case_when(
      name == "I" ~ "bar(theta)[g]",
      name == "CF" ~ "CF[i]",
      name == "V" ~ "V[d]",
      name == "U" ~ "U"
    )
  ) %>%
  print()
```

```{r plot-problem-dag}
ggplot(problem_dag) +
  aes(x = x, y = y, xend = xend, yend = yend) +
  geom_dag_edges() +
  geom_dag_point(
    aes(color = (name == "U"))
  ) +
  geom_dag_text(
    aes(label = pt_label), 
    parse = TRUE, 
    color = "black",
    family = font_fam
  ) +
  scale_color_manual(values = c("TRUE" = primary, "FALSE" = "gray80")) +
  annotate(
    geom = "text",
    label = "Group Ideology \naffects District Voting \nand Candidate Positioning",
    x = 1.25, y = 1,
    hjust = 0, vjust = -0.4,
    size = 3
  ) +
  annotate(
    geom = "text",
    label = 
      TeX("Controlling for $V_{d}$ opens $\\theta_{g} \\rightarrow V_{d} \\rightarrow U \\rightarrow CF_{i}$"),
    parse = TRUE,
    x = 1.2, y = 0,
    size = 3
  ) +
  theme_dag(
    legend.position = "none"
  ) + 
  expand_plot(
    expand_x = expand_scale(c(0.3, 0.3)), 
    expand_y = expand_scale(c(0.2, 0.4))
  ) +
  NULL  
```


```{r plot-problem-dag, include = TRUE, fig.width = 5, fig.height = 3,out.width = "70%", fig.cap = "A DAG that presents district partisanship as a collider along the path from district-party preferences to candidate positioning. Controlling for district partisanship can bias the causal estimate of district-party preferences in several ways. If there is a path $\\theta \\rightarrow P \\rightarrow Y$, then the effect of $\\theta$ does not represent the total effect. In the presence of intermediate confounder $U$, controlling for district partisanship induces collider bias by unblocking the path $\\theta \\leftarrow U \\rightarrow Y$."}
```



## Bayesian Sequential-$g$ Analysis

- What is the problem (defined in the direct effect section above)
- Contribution: $\bar{\theta}_{g}$ is drawn from a prior and can be updated in the model.

### Causal model: controlled direct effects

- what is the problem
- what is ACDE 
- Cite ABS 
- Keep the notation general enough (expectations) so that there are no explicit linear regression functional forms introduced by accident? 
- Identification and estimand


ACDE is posterior distribution of the causal quantity...




This section describes the causal estimand and estimation routine that follows. Sequential-$g$ estimates a quantity called the _average controlled direct effect_, the average effect of a treatment on an outcome, holding fixed a mediator variable for all units under consideration.

Consider a potential outcome where candidate positioning $C$ is affected by district voting $V$ and district-party ideology $T$, or $C(T, V)$. The controlled direct effect imagines that we can intervene on both $T$ and $V$, varying the value of $T$ between $t$ and $t'$ while fixing $V = v$. The controlled direct effect is defined for a single unit $i$ as,
\begin{align}
  CDE_{i}(t, t', v) &= C_{i}(t, v) - C_{i}(t', v),
  (\#eq:PO-CDE)
\end{align}
or, how would $C_{i}$ change if we could vary $t$ without influencing $v$ in the process? The dependence of district voting $V$ on district-party ideology $T$ is shown by the causal graph in Figure \@ref(fig:plot-problem-dag). A model that estimates the _total_ effect of district-party ideology will fail to differentiate the fraction of the effect flowing through path $T \rightarrow C$ from the fraction of the effect through path $T \rightarrow V \rightarrow C$. However, simply controlling for $V$ will not isolate the direct effect, since it can open back-door paths from $T$ to $C$ through confounders represented by $U$ [@montgomery-et-al:2018:colliders]. If there are variables that affect aggregate district voting that are independent of district-party ideology, such as valence features from unrelated prior candidates, post-treatment conditioning on the district vote can create confounders unintentionally. Sequential-$g$ is a special case of a broader class of models (structural nested mean models) that measure direct effects by subtracting intermediary effects without creating collider bias [@acharya-blackwell-sen:2016:direct-effects; @vansteelandt:2009:direct-effects]. 

In order to implement a sequential-$g$ routine, we need to specify valid models that separately identify the mediator-outcome relationship (the total effect of district voting on candidate positioning) and the treatment-outcome relationship (the total effect of district-party ideology on candidate positioning). This twin identification is formalized using an assumption of _sequential ignorability_, or sequential unconfoundedness [@robins-greenland:1994:sequential-ignorability]. This means that unit potential outcomes $C_{i}(t, v)$ are independent of treatment, conditional on pre-treatment covariates $X_{i}$,
\begin{align}
  C_{i}(t, v) \perp \!\!\! \perp T \mid X_{i} = x
\end{align}
and secondly that potential outcomes are independent of the mediator, conditional on treatment, pre-treatment covariates, and _intermediate covariates_ $Z_{i}$ that may affect the mediator separately from $T$ and $X$. 
\begin{align}
  C_{i}(t, v) \perp \!\!\! \perp M \mid T_{i} = t, X_{i} = x, Z_{i} = z
\end{align}



```{r create-g-dag}
g_dag <- 
  dagify(
    CF ~ I + V + Z + X + U1 + U2,
    V ~ I + X + Z + U1,
    Z ~ I + X,
    I ~ X + U2,
    exposure = "I", 
    outcome = "CF",
    coords = tribble(
      ~ name,  ~ x, ~ y,
      "I",       1,   2,
      "CF",       3,   1,
      "Z",       1,   0,
      "V",       2,   0,
      "X",       0,   1,
      "U1",      3, 0,
      "U2",      2.25,   2
    )
  ) %>%
  tidy_dagitty(layout = "auto") %>%
  mutate(
    label = case_when(
      name == "V" ~ "Past Presidential Vote",
      name == "I" ~ "Partisan Ideology",
      name == "CF" ~ "Candidate Position",
      name == "X" ~ "Pre-Treatment Confounders",
      name == "Z" ~ "Intermediate Confounders"
    ),
    pt_label = case_when(
      name == "V" ~ "V[d]",
      name == "I" ~ "bar(theta)[g]",
      name == "CF" ~ "CF[i]",
      name == "X" ~ "X[d]",
      name == "Z" ~ "Z[d]",
      name == "U1" ~ "U1",
      name == "U2" ~ "U2"
    )
  ) %>%
  print()
```

```{r g-dags}
base_dag <- g_dag %>%
  ggplot() +
  aes(x = x, y = y, xend = xend, yend = yend) +
  coord_cartesian(ylim = c(-0.25, 2.25)) +
  theme_mgd_dag() +
  labs(x = NULL, y = NULL) +
  expand_plot(
    expand_x = expand_scale(c(0.2, 0.2)), 
    # expand_y = expand_scale(c(0.2, 0.2))
  ) +
  NULL

mediator_dag <- base_dag +
  geom_dag_point(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE),
    color = "gray"
  ) +
  geom_dag_edges(
    data_directed = filter(g_dag, name %in% c("U2", "U1") == FALSE)
  ) +
  geom_dag_text(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE), 
    aes(label = pt_label),
    parse = TRUE,
    size = 3.5,
    color = "black"
  ) +
  labs(title = "\nStage 1", subtitle = "Identifies mediator effect\n") +
  NULL

exposure_dag <- base_dag +
  geom_dag_node(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE),
    internal_color = "gray",
    color = "white"
  ) +
  geom_dag_point(
    data = filter(g_dag, name %in% c("X", "I", "CF")),
    color = "gray"
  ) +
  geom_dag_edges(
    data_directed = g_dag %>%
      filter(
        to %in% c("Z", "V") | (name == "Z" & to == "CF"), 
        name %in% c("U1", "U2") == FALSE
      ),
    edge_linetype = "dashed", 
    edge_color = "gray"
  ) +
  geom_dag_edges(
    data_directed = g_dag %>%
      filter(
        (name %in% c("U1", "U2", "Z", "V")) == FALSE, 
        to %in% c("I", "CF")
      )
  ) +
  geom_dag_text(
    data = filter(g_dag, name %in% c("U1", "U2") == FALSE),
    aes(label = ifelse(name == "CF", "b(CF)[i]", pt_label)),
    color = "black",
    parse = TRUE,
    size = 3.5
  ) +
  labs(
    title = "\nStage 2", 
    subtitle = "Identifies controlled direct effect\nof treatment using demediated outcome"
  ) +
  NULL

confounding_dag <- base_dag +
  geom_dag_point(aes(color = name %in% c("U2", "U1"))) +
  geom_dag_edges() +
  geom_dag_text(
    aes(label = pt_label), 
    parse = TRUE, 
    size = 3.5,
    color = "black"
  ) +
  theme(legend.position = "none") +
  scale_color_manual(values = c("TRUE" = primary, "FALSE" = "gray")) +
  labs(title = "Violations of Sequential Ignorability", 
       subtitle = "In stage 1 (U1) and stage 2 (U2)")
```

```{r plot-g-dag}
g_layout <- "
AABB
#CC#
"

wrap_plots(
  A = mediator_dag, B = exposure_dag, C = confounding_dag, 
  design = g_layout
)
```

Figure&nbsp;\@ref(fig:plot-g-dag) visualizes the modeling assumptions for sequential-$g$ estimation using causal graphs, which helps explain how to implement the routine. The left panel shows the stage-one model, which estimates the effect of past voting $V$ (the mediator) on candidate positioning $C$ (the outcome). This first stage conditions on district-party preferences $T$, pre-treatment confounders $X$, and intermediate confounders $Z$, all of which are necessary to identify the causal effect of the mediator. 

```{r plot-g-dag, include = TRUE, fig.width = 9, fig.height = 10, out.width = "100%", fig.cap = "Causal graphs describing the modeling problem and sequential-$g$ estimation. The stage 1 graph identifies the effect of the past district voting ($V_{d}$) on candidate positioning ($CF_{i}$). The stage 2 treatment-outcome model subtracts the district vote effect from candidate positions and identifies the effect of district-party ideology $\\bar{\\theta}_{g}$ on the demediated CF score $b(CF)_{i}$, which is equivalent to the controlled direct effect on the raw CF score. The final graph shows where unadjusted confounders violate the nonparametric causal identification assumptions in stage 1 ($U1$) and in stage 2 ($U2$)."}
```


After estimating the mediator's effect on the outcome, the outcome variable is _demediated_ by subtracting the mediator effect from the outcome variable. The center panel represents this demediation step by rewriting the outcome variable as $b(C)$, the demediated value of $C$.^[
  The exact demediation operation is shown below in Equation&nbsp;\@ref(eq:blipdown-function).
]
The stage-two model then estimates the effect of district-party preferences $T$ on the demediated candidate positions, controlling for pre-treatment covariates $X$.
Demediating the outcome suppresses the path from $V$ to $b(C)$ because (by sequential unconfoundedness) there is no longer any systematic variation between the mediator and the outcome. As such, there is no need to adjust for $V$, since it has no systematic effect on $b(C)$ after demediation. 
Furthermore, although there remains a causal effect from the intermediate confounders $Z$ to candidate positions, the stage-two model does not adjust for these confounders to avoid post-treatment bias in the estimate of the CDE.
This stage-two model recovers the controlled direct effect of $T$ on $C$.

It is worth noting here that if we estimate the stage-two model using the natural value of $C$ rather than the demediated $b(C)$, we would obtain the total effect of $T$ (the conditional average treatment effect) rather than the controlled direct effect. This can be valuable, since the difference between the total effect and the controlled direct effect are an indirect indicator of how much of the total effect flows through a mediator variable.

The final panel shows where unmeasured confounding can violate the sequential unconfoundedness assumption. The stage-one model identifies the causal effect of the mediator, so if an unmeasured variable (represented in the future by $U1$) affects both the mediator and the outcome, the mediator's effect is not identified. Similarly, the stage-two model does not identify the effect of $T$ on $b(C)$ if they share an unmeasured confounder $U2$.
Unmeasured variables in other locations of the graph certainly exist, but they do not violate sequential unconfoundedness unless they can be represented by an open back-door path through $U1$ or $U2$.^[
  For instance, a variable $W$ may be a common cause of $X$ and $C$, thus creating the path $T \rightarrow X \rightarrow W \rightarrow C$, but it does not confound the effect of $T$ because conditioning on $X$ blocks the path. 
  Additionally, although intermediate confounders $Z$ are presented as descendants of group policy ideology $T$, intermediate confounders do not necessarily have to be affected by $T$ (though they can be). They only need to be confounders of the mediator-outcome relationship.
]
There are functional form considerations however---biases may remain if the functional forms for confounders $X$ and $Z$ are inappropriate.^[
  I plan to investigate more flexible functional forms in the near future.
]
<!------- TO DO ---------
- functional forms comment
------------------------->

<!------- TO DO ---------
- way bigger emphasis on the contribution of the design.
  other analysis do this kind of observables setup, but they don't
  deal with the causal estimand and the explication of assumptions.
------------------------->

<!------- TO DO ---------
- Discuss potential violations of assumptions
- Simulate violated assumptions by way of correlated error parameters?
------------------------->

### Linear sequential-$g$

<!-- As mentioned above, I estimate average controlled direct effects separately for incumbents, challengers, and open seat candidates in two parties, totaling six routines altogether.  -->
I write a general model that applies regardless of which subset of data is being used. 
Because the estimation in every data subset proceeds in two stages, I use subscript some parameters $1$ and $2$ to indicate that they are not fixed across model stages.

<!------- TO DO ---------
- separate parties
- incumbency
------------------------->

The first stage is a mediator-outcome model, predicting the CF score of candidate $i$ within group $g$, where a group is a combination of district $d$ and party. 
Because I estimate separate models for each party, each model sees data from only one group per district.
Nonetheless, I use separate $g$ and $d$ subscripts to denote which variables have the potential to vary by groups within districts.
We set up the sequential-$g$ method to control for the previous Republican presidential vote share in district $d$, denoted $\mathit{pvote}_{g}$.
This is done with the following multilevel regression model.
\begin{align}
\begin{split}
  \mathrm{CF}_{i} &= 
    a_0 + 
    \eta \bar{\theta}_{g[i]} + 
    \mu \mathrm{pvote}_{d[i]} + 
    \mathbf{x}_{d[i]}^{\intercal}\beta +
    \mathbf{z}_{d[i]}^{\intercal}\gamma +
    \alpha_{d[i]} + \epsilon_{i} \\
  \alpha_{d} &\sim \text{Normal}\left(0, \sigma_{\alpha}\right) \\
  \epsilon_{i} &\sim \text{Normal}\left(0, \sigma_{\epsilon}\right)
\end{split}
(\#eq:med-model)
\end{align}
This model identifies the effect of the presidential vote, $\mu$, under the identification assumption of sequential ignorability and the statistical assumptions of linearity and no interactions.
<!------- TO DO ---------
- check on these assumptions
------------------------->
The group ideal point $\bar{\theta}_{g}$ is included in the regression as a control, so the coefficient $\eta$ is estimated as a nuisance parameter, as are the coefficients $\beta$ for district-level pre-treatment confounders $\mathbf{x}_{d}$, the coefficients $\gamma$ for district-level intermediate confounders $\mathbf{z}_{d}$, and constant $a_{0}$.
Because the mediator is measured at the district level, I include a district error term $\alpha_{d}$ in addition to the candidate-level error term $\epsilon_{i}$.
The multilevel model accounts correlated error among candidates in the same district, similar to clustering standard errors when a treatment is dosed at the cluster level.


Sequential-$g$ estimates the controlled direct effect of treatment by purging the DV of the mediator effect.
This is done by predicting the outcome variable as if the mediator were fixed for all units, which purges the outcome of all systematic variation caused by the mediator variable. 
This can be done by predicting the outcome under a fixed mediator value directly or by demediating the outcome directly using an estimate of the demediation function.
Because the first stage is a linear model, the demediation function has a straightforward parametric definition,
\begin{align}
  \delta_{d} &= \mu \left(\mathrm{pvote}_{d} - \mathrm{pvote}'\right)
  (\#eq:blipdown-function)
\end{align}
where $\mathit{pvote}'$ is the reference value for the mediator where all units are fixed, and $\mu$ is the mediator's effect from Equation \@ref(eq:med-model).
The demediation function represents the effect setting district $d$'s presidential vote to its observed value compared to the reference value $\mathit{pvote}'$.
Because the previous presidential vote varies across districts, so too does the demediation function.^[
  In any case where the reference value for the mediator is zero, this expression reduces to $\mu \mathit{pvote}_{d}$, and an observed value of zero implied a demediation function of zero.
]
We choose a reference value of $0.5$, an even vote split between the Republican and Democratic presidential vote shares in the previous election.
The demediation function can be more complex if the mediator's effect on the outcome is modeled with a more complex model containing interactions or nonlinearities.
We calculate the demediated outcome $b(CF)_{i}$ by subtracting each district's demediation function from its observed outcome value,
\begin{align}
  b\left(\mathrm{CF}\right)_{i} &= \mathrm{CF}_{i} - \delta_{d}
  (\#eq:blipdown-outcome)
\end{align}
Because the mediator is fixed for a given district, all candidates in a district have the same demediation function, regardless of their original CF score.
The demediated outcome value is equivalent to the outcome under a fixed mediator value,
\begin{align}
\begin{split}
  b\left(\mathrm{CF}\right)_{i} &= \mathrm{CF}_{i} - \delta_{d} \\
  b\left(\mathrm{CF}\right)_{i} &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \mathrm{pvote}_{d[i]} + 
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} -
    \mu \left(\mathrm{pvote}_{d[i]} - \mathrm{pvote}'\right) \\
  &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \left(\mathrm{pvote}_{d[i]} - \mathrm{pvote}_{d[i]} + \mathrm{pvote}'\right) +
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
  &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \mathrm{pvote}' + 
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
  &= 
    a' + 
    \eta \bar{\theta}_{g[i]} +
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
\end{split}
(\#eq:med-model-blipped)
\end{align}
which makes it clearer to see how the demediation step subtracts the mediator variation from the outcome, absorbing the non-varying mediator into the new constant $a'$.

The demediated outcome is then used in the second stage estimation of the controlled direct effect.
The second stage is different from the first stage in two ways.
First, because we fixed the mediator value in calculating the transformed outcome variable, there is no more variation across observations that can be attributed to the mediator.
As such, it is omitted from the equation.
Second, intermediate confounders are omitted because they are unnecessary to identify the effect of district-party ideology, and they could induce collider bias if included.
This new equation is,
\begin{align}
\begin{split}
  b\left(\mathrm{CF}\right)_{i} = 
    a_{1} +
    \tau \bar{\theta}_{g} + 
    \mathbf{x}^{\intercal}_{g[i]}\omega + 
    \nu_{d[i]} + u_{i} \\
  \nu_{d} &\sim \text{Normal}\left(0, \sigma_{\nu}\right) \\
  u_{i} &\sim \text{Normal}\left(0, \sigma_{u}\right)    
\end{split}
(\#eq:trt-model)
\end{align}
where $a_{1}$ is a constant, $\tau$ is the coefficient for district-party ideology, $\omega$ are coefficients for district-level pre-treatment confounders $\mathbf{x}_{d}$, $\nu_{d}$ is a district error term, and $u_{i}$ is a candidate error term.
Because the presidential vote effect has been removed from the dependent variable, any treatment effect mediated by the presidential vote is not recoverable by the second stage equation.
As such, $\tau$ measures the average controlled direct effect of a one-unit increase in district-party ideology.
More generally, the ACDE of setting district-party ideology from $\bar{\theta}'$ to $\bar{\theta}$ is as follows.
\begin{align}
  ACDE(\tau, \bar{\theta}, \bar{\theta}') &= \tau \left(\bar{\theta} - \bar{\theta}'\right)
  (\#eq:general-ACDE)
\end{align}
Again, the formula for the ACDE depends on the model specification.
The form in \@ref(eq:general-ACDE) applies to a linear model with no interactions, but a more complex model would entail a more complex formula.


### Bayesian structural modeling

The key methodological innovation in this chapter is embedding the sequential-$g$ method in a Bayesian framework.
Chapter \@ref(ch:causality) describes a number of special advantages for Bayesian causal modeling, stemming from the fact that Bayesian inference allows the researcher to describe their information about causal effects using the intuitive of language of probabilistic inference: the treatment effect is _probably_ greater than $x$, where "probably" has a direct translation to approximate cumulative probabilities from posterior samples.

The most important feature of Bayesian causal inference for this chapter is the fact that one posterior distribution quantifies uncertainty in all parameters from the multi-stage sequential-$g$ method.
This is valuable because uncertainty in stages 1 and 2 are directly related to one another. 
The average controlled direct effect of district-party ideology in stage 2 is estimated using demediated CF score, which is calculated using the demediation function, which is itself a function of stage 1 model coefficients.
Substantively, the ACDE should have a larger magnitude whenever the indirect effect through the mediator has a smaller magnitude, holding the total effect magnitude constant.
<!------- TO DO ---------
- is this true?
------------------------->
<!-- , but unfortunately this estimator does not incorporate the additional uncertainty introduced by the fact that the key independent variable, district-party ideology, is an estimate from a separate measurement model. -->
Whereas @acharya-blackwell-sen:2016:direct-effects derive an analytical variance estimator for the second stage coefficients or advocate for bootstrapped estimation, the posterior distribution from the Bayesian model captures all variances and covariances among model parameters by its nature.
Inferences about the ACDE can be expressed by marginalizing the posterior distribution with respect to these auxiliary model parameters, isolating the remaining dimension of the posterior corresponding to the ACDE.
Letting $\boldsymbol{\pi}$ represent all auxiliary model parameters, and using the definition of the ACDE in Equation \@ref(eq:general-ACDE), the posterior distribution for the ACDE is given by
\begin{align}
  \p{\tau \left(\bar{\theta} - \bar{\theta}'\right) \mid \mathbf{y}} 
  &= 
  \int \p{\tau \left(\bar{\theta} - \bar{\theta}'\right), \boldsymbol{\pi} \mid \mathbf{y}} \diff \boldsymbol{\pi},
  (\#eq:post-acde)
\end{align}
which is a the distribution of ACDE values that condition on the observed data and marginalize over the associated auxiliary parameter values.
In practice, we use MCMC samples to approximate this posterior distribution by picking two fixed values of $\bar{\theta}$ and $\bar{\theta}'$, extracting posterior samples for $\tau$, and calculating $\tau \left(\bar{\theta} - \bar{\theta}'\right)$ for each MCMC sample iteration.
In cases where $\bar{\theta} - \bar{\theta}' = 1$, the ACDE is equal to $\tau$, so posterior samples for $\tau$ are sufficient to characterize that posterior.
Posterior expectations for the ACDE can be calculated, up to Monte Carlo error, by averaging the ACDE values from a draw of MCMC samples.

<!------- TO DO ---------
- should this go in Ch 3?
------------------------->
The joint posterior distribution is also essential for incorporating uncertainty in district-party ideal points themselves.
The IRT model in Chapter \@ref(ch:model) does not estimate district-party ideal points exactly. 
Instead, ideal points are estimated only up to a posterior distribution, with uncertainty that reflects both prior ignorance and a finite sample of polling data.
<!------- TO DO ---------
- typically, people do propagated uncertainty
------------------------->
To estimate the effect of district-party ideology on candidate positioning, the causal analysis incorporates measurement error in ideal points "the Bayesian way," where posterior uncertainty from one analysis becomes prior uncertainty in later analyses.
One way to do this would be to build one joint model for the measurment of 
Rather than jointly estimate the ideal point model and all subsequent causal analyses, which would be an overwhelming feat of model-building and estimation, 
This prior is constructed by defining the group ideal point $\bar{\theta}_{g}$ as an element of $\Theta$, the vector of all group ideal points.
I then specify a multivariate Normal prior on the vector of ideal points.
\begin{align}
  \Theta &\sim 
    \mathrm{MultiNormal}\left( \hat{\Theta}, \hat{\Sigma}_{\Theta} \right) %_
  (\#eq:theta-prior)
\end{align}
The parameters in the prior are estimated from MCMC samples for the ideal points. 
The mean vector $\hat{\Theta}$ contains MCMC mean for each ideal point, and the matrix $\hat{\Sigma}_{\Theta}$ contains variances for each ideal point and covariances between any two ideal points.
Because the IRT model partially pools ideal points using a hierarchical Normal regression, the multivariate Normal prior is a reasonable stand-in for representing prior ideal point uncertainty in causal analyses.

Including ideal point uncertainty as a prior distribution effectively adds a measurement error model overtop to the sequential-$g$ analysis. 
Although @acharya-blackwell-sen:2016:direct-effects describe a variance estimator and a bootstrap method for dealing with multi-stage modeling uncertainty, neither of these methods is naturally suited to a measurement error context where an additional layer of ideal point uncertainty is represented in MCMC samples.
Past research has explored the use of inverse-variance weighting to downweight observations with greater ideal point uncertainty,
<!------- TO DO ---------
- who?
------------------------->
but that method accomplishes essentially the same goal as a prior distribution, except it throws away all information about the covariance covariance between any two ideal points.
<!------- TO DO ---------
- cite?
------------------------->
More recently, researchers have employed methods of "uncertainty propagation" methods, where the researcher estimates an uncertainty quantity, simulates values from the quantity's posterior distribution, and pushes those simulated values through a downstream analysis. 
Quantities of interest are then averaged across the posterior simulations [see @kastellec-et-al:2015:scotus-electoral-connection p. 791; @caughey-warshaw:2018:dynamic-responsiveness p. 6; @caughey-warshaw:2019:subnational-opinion-review p. 360].
This is similar in spirit to "multiple overimputation" [@blackwell-et-al:2017:measurement-error], which creates "imputation datasets" by iteratively replacing mismeasured observations with draws from their posterior distribution.
This project regards these propagation methods as insufficiently Bayesian because they "cut" the flow of information between models: model 1 informs model 2, but model 2 can never inform model 1 [@plummer:2015:bayesian-cuts].
This can be an undesirable modeling property if the causal model can inform the measurement model [@treier-jackman:2008:latent-democracy].
In this project, if ideal points are related to candidate positioning, and ideal points are measured with error, then candidate positions can be informative about ideal points.
Even if the causal analysis does not narrow the marginal distributions for ideal points, the posterior distribution will reflect the correlation between ideal points and other parameters.
By specifying the prior directly and updating the parameters, there is no need for any additional imputation steps or post-estimation model averaging [@gelman-hill:2006:multilevel p. 542].

<!------- TO DO ---------
- priors for other model params
------------------------->

The Bayesian sequential-$g$ approach, of course, requires priors for other model parameters.
Coefficients for linear predictors in stages 1 and 2 are given Normal priors that are proper but overly diffuse, to avoid biasing treatment effects by over-regularizing covariates [@hahn-et-al:2018:regularization-confounding].
\begin{align}
\begin{split}
  a_0, \eta, \mu, \beta, \gamma &\sim \text{Normal}\left(0, 10 \right) \\
  a_{1}, \tau, \omega &\sim \text{Normal}\left(0, 10 \right)
\end{split}
(\#eq:g-coef-priors)
\end{align}
Both modeling stages contain Normal district-level error terms, with estimated variances that facilitate partial pooling. 
These variances are themselves given half-Cauchy priors with weakly informative scale parameter values that are about half the range of the raw outcome data within each party.
\begin{align}
\begin{split}
  \alpha_{d} &\sim \text{Normal}\left(0, \sigma_{\alpha} \right) &
    \sigma_{\alpha} &\sim \text{Half-Cauchy}\left(0, 2 \right) \\
  \nu_{d}  &\sim \text{Normal}\left(0, \sigma_{\nu} \right) &
    \sigma_{\nu} &\sim \text{Half-Cauchy}\left(0, 2 \right)
\end{split}
(\#eq:g-ranef-priors)
\end{align}
And finally, each stage of the model has a Normal error term for candidates within districts. 
The variances for these errors are given half-Cauchy priors with wider scale values than the districts errors, since residual variation between any two candidates is likely larger than the variation between average candidates in any two districts.
\begin{align}
\begin{split}
  \epsilon_{i} &\sim \text{Normal}\left(0, \sigma_{\epsilon} \right) &
    \sigma_{\epsilon} &\sim \text{Half-Cauchy}\left(0, 5 \right) \\
  u_{i} &\sim \text{Normal}\left(0, \sigma_{u} \right) &
    \sigma_{u} &\sim \text{Half-Cauchy}\left(0, 5 \right)
\end{split}
(\#eq:g-resid-priors)
\end{align}



### Causal inference with multilevel data

The research question in this chapter presents us with multilevel data: how is the ideological positioning of primary candidates affected by the policy ideology of partisans in their district, when there are potentially multiple candidates per district?
In this scenario, the outcome is a variable specific to an individual candidate $i$, but the treatment is fixed for an entire district-partisan group $g$. 
This introduces a few issues for statistical assumptions and causal assumptions.

On the statistical front, multilevel models bias coefficient estimates when the aggregate errors are not exchangeable.
Mechanically, this is similar to "omitted variable bias" in a single-level regression.
Although this concern is well founded for many multilevel models, for these models we can be less concerned.
Because all predictors in these regressions are measured at the district level, the district error term is analogous to an error term that we would obtain by averaging every candidate's CF score within a district-party group and running a single-level regression on those averages.
Both of these model specifications require an exchangeable errors assumption at the district level.
The only difference for the models in this analysis is the additional candidate-level errors, but this too is a non-issue. 
Averaging candidate data within each district would invoke a similar assumption about the exchangeability of candidates given the district, otherwise it would be inappropriate to average data within a district.

Even though the multilevel model has similar assumptions as a regression on averages, it has certain benefits that are convenient for these data.
Because the number of candidates in a district isn't fixed across all districts, we would expect heteroskedasticity in a regression-on-averages model, since some districts would have higher variances due to fewer candidates.
In the extreme case, if a district contained only one unopposed primary candidate, a naïve estimator would be unable to distinguish district-level variance from candidate-level variance.
The multilevel model addresses this by estimating the distributions of district errors and candidate errors simultaneously, enhancing the model's ability to recognize when larger district errors are caused by signal versus noise.
Errors from smaller districts borrow more information from the overall distribution of districts, downweighting the contributions of smaller districts by shrinking their error terms toward a mean of zero.
This has a similar intuition as a weighted least squares regression on the district-averaged data, where groups with more observations are more informative about global parameters and receive greater weight.
This is yet another example where priors stabilize pathological model behavior, underscoring the flexibility afforded by Bayesian model-building for confronting the idiosyncrasies of a dataset with tactics that are both intuitive and feasible.
At a technical level, the model is able to avoid estimating individual random effects at all through a clever model parameterization that marginalizes over the distribution of district effects, which I explain in Section \@ref(sec:stan-g).

The multilevel data structure also raises causal inference issues that are worth clarifying.
As with many causal models where treatments are assigned to clusters of observations, it makes sense to consider SUTVA as violated within a cluster: there is no way for one candidate in a district to be treated by a different district-party ideology than other candidates.^[
  Candidates may vary in their ability to perceive district-party ideology, but that might also be described as an issue of treatment compliance or treatment effect heterogeneity.
]
The positioning of one candidate may also affect the positioning of another, which could violate the "no interference" component of SUTVA. 
Under this violation, the treatment effect at the individual level is not identified.
If SUTVA holds _between_ groups, however, it is possible to identify a treatment effect by considering average effects across groups [@Hill:2013:multilevel-causal-inf]. 
In potential outcomes notation, even if we can define potential outcomes at the individual level ($\mathit{CF}_{i}(\bar{\theta}_{g[i]})$), the lowest level where we could credibly _identify_ treatment effects would be the group level, where the potential outcome for a group is the average outcome within the group ($\overline{\mathit{CF}}_{g}\left(\bar{\theta}_{g}\right)$).
This is consistent with the multilevel model setup that we have so far, where the ACDE is a function of aggregate data and aggregate parameters only (see Equation \@ref(eq:general-ACDE)).

There are a few additional considerations for causal inference with hierarchical data that, although I do not pursue these threads in this project, could be relevant for future work with similar data.
A correlation between treatment effects and group size may arise if a crowded primary field causes larger treatment effects because stiffer competition leads candidates to be more responsive to district-party ideology.
On the other hand, more crowded fields would lead to smaller treatment effects if candidates take heterogeneous ideological positions to differentiate themselves.
If treatment effects are correlated with group size, then the average causal effect for a candidate is not equivalent to average difference among groups.
Instead, the average effect for candidates must be a size-weighted average of group effects [@Hill:2013:multilevel-causal-inf].
I do not pursue this possibility in this project because these dynamics are not identifiable with data on primary candidates only, since incumbents may take ideological positions to deter challengers even if no challengers actually emerge.
As such, the observed number of candidates in a district may not capture the true degree of primary threat [@hirano-et-al:2010:primary-polarization; @maisel-stone:1997:candidate-emergence; @stone-mailsel:2003:potential-candidate-calculus].

One additional consideration for group-level effects is the possibility that group size affects treatment assignment.
This may be true if the long-run dynamics of primary competition within a district-party have feedback effects on local ideology, for instance if partisan constituents become more ideologically aware by experiencing stronger intra-party competition in their district, or less ideological after a long period of representation by a single incumbent with little primary competition.
There is evidence that primaries contain more ideological campaign content in certain periods of heightened partisan mobilization [@boatright:2013:getting-primaried], which could increase voters' ideological awareness as well.
Whether voters are responding to primary competition in the district _per se_ or to a national state of partisan agitation is an interesting but thoroughly challenging question for future researchers to explore, were they to extend the data and methods in this project to a greater number of election cycles and dynamic causal modeling approaches [e.g. @blackwell-glynn:2018:causal-TSCS; @imai-kim:2019:fixed-effects-causal-inference].

<!-- If treatment is correlated with X _by design_(?) or otherwise(?), such as blocking along a key covariate like income, can include block-specific means of the treatment variable [@Hill:2013:multilevel-causal-inf]; Bafumi and Gelman, Raudenbush -->

### Model implementation in Stan {#sec:stan-g}

As is common with Bayesian modeling, the flexibility to tackle idiosyncrasies in data require careful computational implementations.
The Bayesian sequential $g$ model can be fitted to multilevel data with many small groups thanks to stabilizing priors, but implementation in Markov chain Monte Carlo algorithms can present additional complications.
For individual districts containing few candidates, the district error terms are only weakly identified against the candidate error terms, inducing correlations in the posterior distribution that lead to slower MCMC exploration of the parameter space. 

I expedite MCMC performance through a multilevel model parameterization that marginalizes over the distribution of district random effects, recovering the same likelihood without the need to sample each district effect separately.
The original model laid out in Equations \@ref(eq:med-model) through \@ref(eq:trt-model) draws the outcome variable as a univariate Normal variable conditional on the regression function and district membership. 
In other words, candidates ideal points are independent Normal variables, after conditioning on group membership.
By marginalizing over the distribution of district random effects instead of conditioning on a specific group, candidate ideal points are correlated multivariate Normal draws, with covariances that reflect the correlation among candidates within the same district. 
This parameterization retains the same variance decomposition as before, without the need to explicit sample random effects that burden the MCMC algorithm.

I walk through the multivariate parameterization beginning with the first stage model.
Instead of drawing the CF score for each candidate, I draw CF scores for all candidates as an $N$-vector $\overrightarrow{CF}$ from a multivariate Normal distribution with a mean vector given by the linear regression in Equation \@ref(eq:med-model) and an $N \times N$ variance–covariance matrix $\mathbf{V}_{1}$.
\begin{align}
\begin{split}
  \overrightarrow{CF} &\sim \text{MultiNormal}\left( 
    a_0 + 
    \eta \bar{\theta}_{g[i]} + 
    \mu \mathrm{pvote}_{d[i]} + 
    \mathbf{x}_{d[i]}^{\intercal}\beta +
    \mathbf{z}_{d[i]}^{\intercal}\gamma,
    \mathbf{V}_{1} %_
  \right)
\end{split}
(\#eq:multinorm-y)
\end{align}
The regression omits the district effect, since it is mean $0$ and does not directly affect the conditional mean.
The random effect distribution instead appears in the covariance structure of $\mathbf{V}_{i}$ in accordance with the multilevel model's variance assumptions.
The total variance for each candidate $i$, located along the diagonal, is the sum of the the district variance $\sigma^{2}_{\alpha}$ and the residual candidate error variance $\sigma^{2}_{\epsilon}$.
The off-diagonal elements are determined by the group membership of any two candidates.
If two primary candidates run in the same district, their ideal point covariance is $\sigma^{2}_{\alpha}$.
Two candidates in different districts are assumed to be independent with a covariance of $0$, since they share no correlated district-level error.
This gives the covariance matrix a block-diagonal structure: total variance along the diagonal, and blocks of off-diagonal covariance terms that model correlated error between candidates in the same district.
\begin{align}
\begin{split}
  \mathbf{V} &= \begin{bmatrix}
    \sigma^{2}_{\epsilon} + \sigma^{2}_{\alpha} & 
      \sigma^{2}_{\alpha} & 
      0 & \dots & 0 \\
    \sigma^{2}_{\alpha} & \sigma^{2}_{\epsilon} + \sigma^{2}_{\alpha} & 
      0 &  & \vdots \\
    0 & 0 & \sigma^{2}_{\epsilon} + \sigma^{2}_{\alpha} &  & 0 \\
    \vdots & & & \ddots & \sigma^{2}_{\alpha} \\
    0 & \dots & 0 & \sigma^{2}_{\alpha} & \sigma^{2}_{\epsilon} + \sigma^{2}_{\alpha}
  \end{bmatrix}
\end{split}
(\#eq:multinorm-sigmas)
\end{align}
This covariance matrix models the data with the same variance assumptions as the original model parameterization, reducing both the number of parameters explored by the MCMC algorithm and the complexity of the posterior geometry.

Computationally, sampling a multivariate Normal distribution requires inverting the covariance matrix, an operation that grows unfeasibly slow in high dimensional problems.
It is computationally easier to sample a multivariate Normal distribution parameterized by a precision matrix, $\mathbf{Q}_{1} = \mathbf{V}^{-1}$, if an analytical matrix inversion is known.
Fortunately for multilevel models of this sort, the precision matrix can be obtained through the Woodbury matrix identity.
First, let $\mathbf{V}_{1} = \sigma^{2}_{\epsilon}I_{N} + \sigma^{2}_{\alpha}A$, where $I_{N}$ is an $N \times N$ identity matrix, and $A$ is an $N \times N$ symmetric adjacency matrix with cells representing pairs of candidates, equaling $1$ if the candidates run for the same district primary and $0$ if they run in different districts.
This adjacency matrix has the same block-diagonal structure as the covariance matrix $\mathbf{V}_{1}$.
The adjacency matrix can be further decomposed as $A = LL^{\intercal}$, where $L$ is an $N \times D$ matrix whose elements $L_{i, d}$ equal $1$ if candidate $i$ belongs to district $d$ and $0$ if not.
The Woodbury identity states that we can invert this decomposition of $\mathbf{V}_{1}$ as
\begin{align}
  \mathbf{Q}_{1} = \left(\sigma^{2}_{\epsilon}I_{N} + L\sigma^{2}_{\alpha}L^{\intercal}\right)^{-1}
  &= 
  \frac{1}{\sigma^{2}_{\epsilon}}I_{N} - \frac{1}{\sigma^{2}_{\epsilon}}L
  \left(
    \frac{1}{\sigma^{2}_{\alpha}}I_{D} + \frac{1}{\sigma^{2}_{\epsilon}}L^{\intercal}L
  \right)^{-1}
  L^{\intercal}\frac{1}{\sigma^{2}_{\epsilon}}
  (\#eq:woodbury)
\end{align}
where $I_{D}$ is a $D \times D$ identity matrix.


### Data

Pre-treatment confounders consist of district-level demographic indicators for the racial composition, college graduation rate, median income, inequality (Gini), unemployment rate, foreign-born population, and evangelical population, and $\mathbf{z}_{ig}$ currently contains an order-3 polynomial function of candidate $i$'s total campaign receipts.^[
  Note: this isn't a good choice for intermediate confounding, and it should change. Ask me why!
]

<!------- TO DO ---------
- should be a prior measure of relative party campaign spending
------------------------->
<!------- TO DO ---------
- justify covariates with cites?
------------------------->



<!-- Primary Candidacies -->

<!-- CF scores -->
<!-- better than interest group ratings? -->

CF scoreswork by assuming that a donor $i$ contributes to recipient $j$ by maximizing their donation utility over all potential recipients.
The donor chooses a dollar amount $y_{ij}$ subject to contribution limits that maximizes
\begin{align}
  u_{i}(\mathbf{y}_{i}) &= \sum\limits_{j} \left[
    b_{i}\left(y_{ij}\right) - y_{ij}\left(\theta_{i} - \delta_{j}\right)^2
  \right]
\end{align}
where $b_{i}(y_{ij})$ is $i$'s net benefit for contribution $y_{ij}$ (instrumental and/or expressive benefits minus costs), $\theta_{i}$ is the donor's ideal point, and $\delta_{j}$ is the recipient's ideal point.
The term $y_{ij}\left(\theta_{i} - \delta_{j}\right)^2$ is a dollar-weighted function of the ideological distance between donor and candidate ideologies.
The term grows when the ideological distance is greater, meaning that the donor loses more utility by giving to candidates that don't reflect the donor's ideological preferences, and it also grows when the donation amount $y_{ij}$ is larger.
The $b_{i}$ function acts like a donor-level fixed effect, capturing a donor's overall propensity to donate regardless of their ideological proximity to potential recipients.
@bonica:2013:ideology-interests derives a fully parameterized item response theory (IRT) model from this utility framework, estimating latent ideological locations for all donors and all recipients from their contribution patterns.
The IRT scores do not cover as wide of a universe as CF the scores created from correspondence analysis [@bonica:2014:mapping-ideology]. 

<!------- TO DO ---------
- validity conversation!!!
------------------------->



<!-- ### Primary Rules -->

General comment: very difficult to code these.

- law vs. party rules
- for some organizations "open" means there's ANY openness, which can include the McGhee "semi-closed" definition
- most states have the same system for both parties, but some state laws leave it open to parties to modify their rules in the months leading up to the election. 


I take data from Boatright on primaries. 

- 2016: combination of NCSL, Ballotpedia, and OpenPrimaries.org, as of 2020-05-27.


`r knit_exit()`


```{r read-g, eval = FALSE}
g_samples <- 
  here("data", "_model-output", "04-positioning", "pos-g-samples.rds") %>%
  read_rds() %>%
  print()
```

```{r unnest-samples, eval = FALSE}
mediator_samples <- g_samples %>%
  select(party, incumbency, .draw, mediator_samples) %>%
  unnest(cols = mediator_samples) %>%
  ungroup() %>%
  mutate(
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()

direct_samples <- g_samples %>%
  select(party, incumbency, .draw, direct_samples) %>%
  unnest(cols = direct_samples) %>%
  ungroup() %>%
  mutate(
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()

total_samples <- g_samples %>%
  select(party, incumbency, .draw, direct_samples, total_samples) %>%
  unnest(cols = c(total_samples, direct_samples)) %>%
  ungroup() %>%
  mutate(
    indirect_effect = total_effect - direct_effect,
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()
```

I implement the sequential-$g$ routine using candidate data drawn primarily from @bonica:2019:dime, @foster-molina:2016:data, and my own estimates. 

For the dependent variable, I use Bonica's dynamic Dime scores for House primary candidates in election years 2012, 2014, and 2016. These estimates are generated from a data reduction on campaign contributions data, assuming that campaign contributors give money to ideologically proximate candidates.

For the mediator, I use the Republican share of the presidential vote in the prior election, available in the Bonica data for each candidate running for House. This serves as a broad measure of district voting that closely reflects the partisan composition of the district.

For my independent variable, I use my own district-party ideology estimates generated for the post-2012 districting cycle, estimated from ANES and CCES data for years 2012 through 2018.^[
  One feature in this design that needs improvement is that it would be nice to have ideology estimates that evolve more over time, so as not to treat district-party ideology as fixed for an entire redistricting cycle, which is the current setup of the model.
]

Control variables are measured primarily at the congressional district level and are drawn primarily from @foster-molina:2016:data. These covariates include racial, educational, religious, and economic features of districts, which I revisit below. Currently I do not have data on primary institutions included in the routine, which limits what I can say about effect modification in primaries vs. caucuses or as a function of primary openness. This is an important part of the story to include in the future. 




## Findings



```{r read-G-data}
mcmc_dem <- read_rds(here("data", "mcmc", "4-positioning", "g-mcmc_dem.rds"))
mcmc_rep <- read_rds(here("data", "mcmc", "4-positioning", "g-mcmc_rep.rds"))
vb_grid <- read_rds(here("data", "mcmc", "4-positioning", "g-grid-vb.rds"))
```




### District-Party Ideology and Primary Candidate Positioning

I'm running short on time to write these results up gracefully, but here's what we're seeing so far!

```{r g-summaries, eval = FALSE}
mediator_summary <- mediator_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(mediator_effect), 
    conf.low = quantile(mediator_effect, .05), 
    conf.high = quantile(mediator_effect, .95),
    n_samples = n()
  ) %>%
  print()

direct_summary <- direct_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(direct_effect), 
    conf.low = quantile(direct_effect, .05), 
    conf.high = quantile(direct_effect, .95),
    n_samples = n()
  ) %>%
  print()

total_summary <- total_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(total_effect), 
    conf.low = quantile(total_effect, .05), 
    conf.high = quantile(total_effect, .95),
    n_samples = n()
  ) %>%
  print()

indirect_summary <- total_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(total_effect - direct_effect), 
    conf.low = quantile(total_effect - direct_effect, .05), 
    conf.high = quantile(total_effect - direct_effect, .95),
    n_samples = n()
  ) %>%
  print()
```

### Stage 1


```{r, eval = FALSE}
ggplot(mediator_samples) +
  aes(x = mediator_effect) +
  geom_histogram(
    aes(fill = as.factor(party), color = as.factor(party)), 
    position = "identity", alpha = 0.5, bins = 50,
    show.legend = FALSE
  ) +
  facet_wrap( ~ incumbency) +
  scale_fill_manual(values = party_factor_colors) +
  scale_color_manual(values = party_factor_colors)
```

```{r plot-mediator, eval = FALSE}
ggplot(mediator_samples) +
  aes(
    x = mediator_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  # geom_vline(xintercept = 0, color = "gray", size = 0.5) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = mediator_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = mediator_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside"
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.75)) +
  labs(
    title = "Effect of Past Presidential Vote", 
    subtitle = "On Candidate Dime Score",
    y = NULL, x = NULL
  ) +
  NULL
```


Stage 1 estimates the previous presidential vote's effect on candidate ideal points (the mediator-outcome model). Mediator effects in Figure&nbsp;\@ref(fig:plot-mediator) show noisy estimates. A one-unit represents a 100 percent change in Republican vote, whereas most Dime scores for candidates live in the [-2, 2] range. So this regression is getting hardly any signal from the presidential vote. 

This maybe isn't so crazy, since most of the votes vs. ideal point relationship is between rather than within parties. This echoes back to a key finding in [@mccarty-poole-rosenthal:2009:gerrymandering], that the within-party relationship between district vote shares and NOMINATE scores was actually quite weak! It appears that these data find an even weaker relationship between district votes and Dime scores.


```{r plot-mediator, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE,  out.width = "100%", fig.cap = "Mediator findings"}
```

### Stage 2







<!------- TO DO ---------
- old stuff below:...
------------------------->
```{r plot-direct, eval = FALSE}
ggplot(direct_samples) +
  aes(
    x = direct_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  geom_vline(
    xintercept = 0, color = "gray", size = 0.5, linetype = "dashed"
  ) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = direct_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = direct_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside",
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.25)) +
  labs(
    title = "Effects of District-Party Ideology",
    subtitle = "Controlled Direct Effect on Candidate Dime Score",
    y = NULL,
    x = NULL
  ) +
  NULL
```

We're seeing average controlled direct effects that are statistically noteworthy in Figure&nbsp;\@ref(fig:plot-direct). Error bars represent 90 percent intervals,^[
  90 percent intervals are chosen because simulation-based statistics they are more stable estimators of the interval bounds than 95 percent intervals, especially when we don't have a huge number of iterations to work with. 
]
which means that most of our simulations are showing ACDEs that have 95 percent posterior probability above zero. I know that I need to do some rescaling of variables to make these effects more interpretable, and once I do that I will be able to put regularizing priors on these effects so as to guard against overfitting in the inference of the treatment effect. 


```{r plot-direct, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE, out.width = "100%", fig.cap = "ACDE findings"}
```





```{r plot-indirect, eval = FALSE}
ggplot(total_samples) +
  aes(
    x = indirect_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  geom_vline(
    xintercept = 0, color = "gray", size = 0.5, linetype = "dashed"
  ) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = indirect_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = indirect_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside",
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.25)) +
  labs(
    title = "Strength of the District Vote Mechanism",
    subtitle = "Total Effect minus Controlled Direct Effect of District-Party Ideology",
    y = NULL,
    x = NULL
  ) +
  NULL
```

```{r plot-indirect, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE, out.width = "100%", fig.cap = "ATE-ACDE findings"}
```

<!------- TO DO ---------
- parameter constraints!
    - total = direct + indirect
    - p(total) and p(direct), which are estimated, implying a prior for p(indirect).
    - Suppose we constrain the variance of one of these, which of the "free" priors gets a better signal?
------------------------->


### Effect modification by primary rules {#sec:pos-rules}



## Discussion




### Primary Representation

The DAG reveals how confounding affects this conclusion.

- if intermediary groups are the key voice, but intermediaries are sampled from the population, then the population has an effect.
- if the population responds to intermediaries (which might instead be functions of industry, demographics, etc), then the causal effect remains confounded insofar as controlling for demographics does _not_ do a sufficient job.
- draw a dag:
    - positioning ~ ideology, EPN
    - ideology ~ EPN, demographics
    - EPN ~ demographics + u
    - if U also connects to positioning, we're in trouble?


### Bayesian Causal Inference

Flexible sequential-$g$. 




