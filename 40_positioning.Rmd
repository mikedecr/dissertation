# How District-Party Ideology Ideology Affects Primary Candidate Positioning: A Bayesian De-Mediation Model {#ch:positioning}

<!------- TO DO ---------
- what's the latent relationship between local ideology and primary rules?
- does this explain the weird findings by McGhee et al?
- take credit for the Bayesian setup:
    - multilevel setup has a number of advantages for statistical identifiability and estimation
    - priors on ideal points
------------------------->

```{r stopper, eval = FALSE, cache = FALSE, include = FALSE}
knitr::knit_exit()
```


```{r knitr-04-1-positioning, include = FALSE, cache = FALSE}
source(here::here("assets-bookdown", "knitr-helpers.R"))
```

<!-- might need to add math -->

```{r packages-04-positioning, cache = FALSE}
library("knitr")
library("here")
library("magrittr")
library("tidyverse")
library("scales")
library("patchwork")
library("broom")
library("ggdag")
library("latex2exp")

theme_dag <- theme_dag(base_family = font_fam)
```


Do primary elections effectively transmit citizens' policy preferences into government? For this to be true, we should expect that the policy ideology with a partisan constituency to affect the ideological positioning of candidates who run for that party's nomination. This chapter explores the effect of district-party public ideology on the candidates who run to represent that district-party.

It is important to distinguish the influence of the district-party public from the influence of district _partisanship_. Does Senator Susan Collins (R-ME) have a reputation as a moderate Republican senator because the balance of a close numerical balance of Republican and Democratic voters in Maine? Or is it because her Republican constituency in Maine is relatively moderate compared to the Republican constituencies in other states represented by more conservative Senators? Although past research has been interested in the threat of primary challenges as a cause of ideological divergence between partisan legislators [for example @boatright:2013:getting-primaried; @hill:2015:nominating-institution; @hirano-et-al:2010:primary-polarization; @mcghee-et-al:2014:nomination-systems], many of these studies lacked the capability to observe the preferences within local partisan groups as a district construct from aggregate voting patterns. This chapter uses my new measures of district-party ideology to investigate this question in ways that previous research projects could not. 

The effect of district-party ideology on candidate positioning is a challenging causal inference problem. We cannot directly compare the "explanatory power" of district-party ideology and district-level voting by measuring whether one is more strongly correlated with candidate ideal points, because district-level voting behavior is certainly affected by district-party ideology, and it likely mediates the effect of district-party ideology on candidate positioning. Estimating the direct effect of district-party ideology by simply controlling for district voting in a regression is likely to introduce collider bias by conditioning on a post-treatment variable [@greenland-et-al:1999:dags-epidemiology].

This chapter investigates the effect of district-party ideology on primary candidate positions using a sequential-$g$ model, a multistage approach that estimates the direct effect of district-party ideology while holding fixed district-level voting, a likely mediator of the total effect [@acharya-blackwell-sen:2016:direct-effects]. I use causal graphs to illustrate the modeling problem and discuss the assumptions required for identifying the targeted effect, which I adapt to a multilevel context where treatment and mediators exist at different levels of the data hierarchy. Finally, I describe and implement a method for propagating measurement uncertainty through the sequential-$g$ method, since the key independent variable is an uncertain estimate from a measurement model.


## Constituency Preferences and Candidate Positioning

Lit review:

- I have lit review but it isn't well organized right now. I'll summarize some main points:
- classic models of electoral competition view candidate moderation as an electoral benefit. You can make non-moderate positions make sense if you incorporate campaign volunteers, primaries, etc. 
- Researchers find evidence that district-level aggregate voting (e.g.\ the presidential vote) is related to candidate positioning.
- Why do candidates take non-moderate stances in reality? Studies that look into the polarizing effects of primaries find little evidence that primaries matter for candidate positioning, but many of these studies are focused on Congressional incumbents. 
- Studies that include non-incumbent candidates show that many of the empirical implications of the "strategic positioning dilemma" don't receive a lot of evidence. For instance, studies of primary "openness" consistently show basically zero or even reversed relationships to candidate ideology as you would expect from theory.  

<!------- TO DO ---------
- from the prospectus:
------------------------->
The second obstacle preventing a more complete study of primary representation is the failure to incorporate primary candidates' ideal points into the analysis. 
Although ideal point estimates derived from roll-call votes such as [Nominate]{.smallcaps} are a popular tool for measuring politicians' ideological locations [@poole-rosenthal:1997:roll-call-history; @poole:2005:spatial-models], only incumbents cast roll call votes, so these measures are unavailable for non-incumbent candidates.^[
  Studies of candidate positioning that go beyond incumbents sometimes use survey data from challenger candidates [@ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning], but the surveys only interview general election candidates. Furthermore, the rarity of these surveys limits the generalizability of their findings over time.
]
Further, when non-incumbents enter the picture, researchers tend to focus on the positioning of general election candidates rather than primary candidates [@ansolabehere-et-al:2001:candidate-positioning; @canes-wrone-et-al:2002:out-of-step; @burden:2004:candidate-positioning]. Some studies have argued that primary competition leads incumbent legislators to take non-median positions, but these studies do not observe primary candidate positions directly, instead observing the presence or threat of challengers [@burden:2004:candidate-positioning; @brady-han-pope:2007:out-of-step]. Recent advances in ideal point modeling using campaign contributions are a promising path forward [@hall-snyder:2015:ideology; @bonica:2013:ideology-interests; @bonica:2014:mapping-ideology], but they are not designed for the careful study of primary competition and thus contain many "post-treatment" measurement artifacts.
<!------- TO DO ---------
- weaken
------------------------->
<!-- don't diss Bonica if we're going to use him! -->




What to do with the Hopkins/Sniderman theory

- does party's issue emphasis mean parties should collapse, or that variation should track
- Grossman-Hopkins; parties care about issues so they try to position themselves on it
  + read their stuff to see how they quality this
  + do they think districts collapse?
- weighting issues: left groups see fine variation in left members, but republicans are all bunched at zero (Brunell? Linda Fowler?)
- or Sniderman conflicted theory: Democrats are conflicted about appeasing groups, so variation matters. Republicans are conflicted
- THINK about abortion as a toy case
  + if weighting... if not weighting...






## How Partisan Preferences Affect Candidates


### Naive regression

- what is the relationship
- let's control for the thing
- what does this imply?






```{r read-dime, eval = FALSE}
dime <- read_rds(here("data", "_clean", "candidates-x-irt.rds"))
```


```{r simple-regs, eval = FALSE}
simple_regs <- 
  read_rds(here("data", "_model-output", "04-positioning", "simple-regs.rds"))
```



```{r plot-first-look, eval = FALSE}
dime %>%
  filter(
    is.na(recipient_cfscore_dyn) == FALSE &
    is.na(theta) == FALSE
  ) %>%
  ggplot() +
  aes(x = scale(theta), y = recipient_cfscore_dyn) +
  # facet_grid(
  #   str_glue("{cycle} Campaign") ~ fct_relevel(incumbency, "Incumbent")
  # ) +
  facet_wrap(
    ~ str_glue("{cycle} Campaign")
  ) +
  geom_point(
    aes(color = as.factor(party)), 
    size = 1, shape = 1, alpha = 0.5
  ) + 
  geom_smooth(
    aes(fill = as.factor(party)), 
    color = "black",
    method = "lm",
    size = 0.25
  ) +
  scale_y_continuous(breaks = seq(-4, 4, 4)) +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  labs(x = "District-Party Ideal Point", y = "Candidate Dime Score") +
  theme(panel.grid = element_line(color = "gray90")) +
  geom_text(
    data = tibble(
      theta = c(-1.25, 0.25),
      recipient_cfscore_dyn = c(-3, 3),
      text = c("Democrats", "Republicans"),
      cycle = 2012, 
      incumbency = factor("Incumbent")
    ),
    aes(label = text)
  ) +
  # geom_label(
  #   data = simple_regs,
  #   aes(x = (party - 1.5), y = -5 * (party - 1.5), 
  #       label = str_glue("r = {number(sqrt(r.squared), accuracy = .01)}\nb = {number(estimate, accuracy = .01)}\nn = {df + df.residual}")),
  #   color = "black", size = 3
  # ) +
  theme(legend.position = "none")
```

With direct measures of district-party policy ideology, do we get a different topline picture of within-party representation in primaries? Figure&nbsp;\@ref(fig:plot-first-look) shows a descriptive picture of the relationship between district-party ideology and candidate ideology for House primary candidates, the latter measured with dynamic ideal point scores derived from campaign contributions [@bonica:2014:mapping-ideology]. Across incumbents, challengers, and open-seat candidates, in both parties, and across several election cycles, we observe a generally positive relationship between these two measures. As partisan citizens in a district become more conservative, so too do the candidates who run in those districts.


```{r plot-first-look, include = TRUE, fig.width = 8, fig.height = 6, eval = FALSE, out.width= "100%", fig.cap = "Simple comparison of candidate Dime scores against their respective district-party ideal points. Results generally indicate a positive relationship: as partisan constituents in a district hold more conservative policy preferences, candidates running for that party's nomination in the House are also more conservative."}
```


The strength of these relationships vary most dramatically by candidate incumbency status, which could be owed to competitive positioning incentives when, for example, challengers attempt to differentiate themselves ideologically from incumbents in ways that aren't entirely explained by bottom-up ideological pressure from voters [c.f. @ansolabehere-et-al:2001:candidate-positioning; @burden:2004:candidate-positioning]. Incumbent candidates' ideal points are most strongly related to district-party ideology, consistent with a notion that ideological consistency creates a selection effect into incumbency in previous election. 

This descriptive picture informs a few modeling choices during the sequential-$g$ routine. Because incumbency status appears to be a substantial modifier of the relationship between citizen and candidate ideology, I estimate the direct effect of district-party ideology separately for incumbents, challengers, and open seat candidates. By comparison, estimates are quite similar across election cycles, so I pool election cycles into one model with cycle fixed effects rather than estimating entirely separate models for different cycles. And although the descriptive relationships vary modestly across parties, the variables that could confound the relationship between citizen and candidate ideology could differ dramatically across parties. I therefore estimate models for Democrats and Republicans separately. This results in six groups of sequential-$g$ estimates: three incumbency categories $\times$ two major parties.


<!------- TO DO ---------
- whom to attribute to?
------------------------->





<!------- TO DO ---------
- plot vote as f(theta)
------------------------->

```{r, eval = FALSE}
ggplot(dime) +
  aes(
    y = district_pres_vs, x = theta, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    y = "Past Republican Presidential Vote",
    x = "District-Party Ideology"
  ) +
  facet_wrap(~ cycle, ncol = 1) +
  # scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1))
  NULL
```

```{r plot-scattering, eval = FALSE}
(
  ggplot(dime) +
  aes(
    x = district_pres_vs, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "Dynamic Dime Score"
  ) +
  scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1))
) /
((
  ggplot(dime) +
  aes(
    x = district_pres_vs, y = dwnom1, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "DW-Nominate (D1)"
   ) +
   scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1)) +
   scale_y_continuous(limits = c(-1, 1))
) +
(
  ggplot(dime) +
  aes(
    x = dwnom1, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    y = "Dynamic Dime Score", 
    x = "DW-Nominate (D1)"
   ) +
   scale_x_continuous(limits = c(-1, 1))
))
```

Although this descriptive picture is suggestive about the relationship between district-party ideology and candidate ideology, we need more rigorous methods to interrogate a causal relationship. In particular, we should be concerned that district features that promote conservative voters also promote conservative candidates, so background features of districts are important to control. Furthermore, if it is worthwhile for researchers to consider the unique effect of district-party ideology, it is important to demonstrate that it affects candidate positioning above and beyond its intermediate effect on district voting. The sequential-$g$ approach confronts both of these threats to inference. 

<!-- Figure&nbsp;\@ref(fig:plot-scattering) shows... -->

```{r plot-scattering, include = FALSE, fig.width = 5, fig.height = 4, eval = FALSE, out.width= "70%", fig.cap = "Presidential Vote Shares and Ideal Point Measures, 2012--2016"}
```



```{r plot-scatter-by-incumbency, eval = FALSE}
ggplot(dime) +
  aes(
    x = district_pres_vs, y = recipient_cfscore_dyn, 
    color = as.factor(party)
  ) +
  geom_point(alpha = 1, shape = 1) +
  theme(legend.position = "none") +
  scale_color_manual(values = party_factor_colors) +
  labs(
    x = "Past Republican Presidential Vote",
    y = "Dynamic Dime Score"
  ) +
  scale_x_continuous(labels = percent_format(digits = 1), limits = c(0, 1)) +
  facet_wrap(~ str_glue("{incumbency}s"))
```

<!-- put graph here -->
<!-- cces figure -->
<!-- dime vs. party prefs, dime vs. district voting -->
<!-- swap dime for DW-Nominate -->







### The Direct Effect of District-Party Ideology

```{r problem-dag}
problem_dag <- 
  dagify(
    CF ~ I + V + U,
    V ~ I + U,
    exposure = "I",
    outcome = "CF",
    coords = tribble(
      ~ name,      ~ x,    ~ y,
      "I",       1,   1,
      "CF",       3,   1,
      "V",       2,   0,
      "U",      3,      0
    ),
    labels = c(
      "I" = "District-Party Ideology",
      "CF" = "Candidate Positioning",
      "V" = "District Voting"
    )
  ) %>%
  tidy_dagitty() %>%
  # node_parents("CF") %>%
  mutate(
    pt_label = case_when(
      name == "I" ~ "bar(theta)[g]",
      name == "CF" ~ "CF[i]",
      name == "V" ~ "V[d]",
      name == "U" ~ "U"
    )
  ) %>%
  print()
```

```{r plot-problem-dag}
ggplot(problem_dag) +
  aes(x = x, y = y, xend = xend, yend = yend) +
  geom_dag_edges() +
  geom_dag_point(
    aes(color = (name == "U"))
  ) +
  geom_dag_text(
    aes(label = pt_label), 
    parse = TRUE, 
    color = "black",
    family = font_fam
  ) +
  scale_color_manual(values = c("TRUE" = primary, "FALSE" = "gray80")) +
  annotate(
    geom = "text",
    label = "Group Ideology \naffects District Voting \nand Candidate Positioning",
    x = 1.25, y = 1,
    hjust = 0, vjust = -0.4,
    size = 3
  ) +
  annotate(
    geom = "text",
    label = 
      TeX("Controlling for $V_{d}$ opens $\\theta_{g} \\rightarrow V_{d} \\rightarrow U \\rightarrow CF_{i}$"),
    parse = TRUE,
    x = 1.15, y = 0,
    size = 3
  ) +
  theme_dag(
    legend.position = "none"
  ) + 
  expand_plot(
    expand_x = expand_scale(c(0.25, 0.25)), 
    expand_y = expand_scale(c(0.2, 0.4))
  ) +
  NULL  
```



This section describes the causal estimand and estimation routine that follows. Sequential-$g$ estimates a quantity called the _average controlled direct effect_, the average effect of a treatment on an outcome, holding fixed a mediator variable for all units under consideration.

Consider a potential outcome where candidate positioning $C$ is affected by district voting $V$ and district-party ideology $T$, or $C(T, V)$. The controlled direct effect imagines that we can intervene on both $T$ and $V$, varying the value of $T$ between $t$ and $t'$ while fixing $V = v$. The controlled direct effect is defined for a single unit $i$ as,
\begin{align}
  CDE_{i}(t, t', v) &= C_{i}(t, v) - C_{i}(t', v),
  (\#eq:PO-CDE)
\end{align}
or, how would $C_{i}$ change if we could vary $t$ without influencing $v$ in the process? The dependence of district voting $V$ on district-party ideology $T$ is shown by the causal graph in Figure&nbsp;\@ref(fig:plot-problem-dag). A model that estimates the _total_ effect of district-party ideology will fail to differentiate the fraction of the effect flowing through path $T \rightarrow C$ from the fraction of the effect through path $T \rightarrow V \rightarrow C$. However, simply controlling for $V$ will not isolate the direct effect, since it can open back-door paths from $T$ to $C$ through confounders represented by $U$ [@montgomery-et-al:2018:colliders]. If there are variables that affect aggregate district voting that are independent of district-party ideology, such as valence features from unrelated prior candidates, post-treatment conditioning on the district vote can create confounders unintentionally. Sequential-$g$ is a special case of a broader class of models (structural nested mean models) that measure direct effects by subtracting intermediary effects without creating collider bias [@acharya-blackwell-sen:2016:direct-effects; @vansteelandt:2009:direct-effects]. 

```{r plot-problem-dag, include = TRUE, fig.width = 5, fig.height = 3,out.width = "70%", fig.cap = "A DAG that presents district partisanship as a collider along the path from district-party preferences to candidate positioning. Controlling for district partisanship can bias the causal estimate of district-party preferences in several ways. If there is a path $\\theta \\rightarrow P \\rightarrow Y$, then the effect of $\\theta$ does not represent the total effect. In the presence of intermediate confounder $U$, controlling for district partisanship induces collider bias by unblocking the path $\\theta \\leftarrow U \\rightarrow Y$."}
```

In order to implement a sequential-$g$ routine, we need to specify valid models that separately identify the mediator-outcome relationship (the total effect of district voting on candidate positioning) and the treatment-outcome relationship (the total effect of district-party ideology on candidate positioning). This twin identification is formalized using an assumption of _sequential ignorability_, or sequential unconfoundedness [@robins-greenland:1994:sequential-ignorability]. This means that unit potential outcomes $C_{i}(t, v)$ are independent of treatment, conditional on pre-treatment covariates $X_{i}$,
\begin{align}
  C_{i}(t, v) \perp \!\!\! \perp T \mid X_{i} = x
\end{align}
and secondly that potential outcomes are independent of the mediator, conditional on treatment, pre-treatment covariates, and _intermediate covariates_ $Z_{i}$ that may affect the mediator separately from $T$ and $X$. 
\begin{align}
  C_{i}(t, v) \perp \!\!\! \perp M \mid T_{i} = t, X_{i} = x, Z_{i} = z
\end{align}



```{r create-g-dag}
g_dag <- 
  dagify(
    CF ~ I + V + Z + X + U1 + U2,
    V ~ I + X + Z + U1,
    Z ~ I + X,
    I ~ X + U2,
    exposure = "I", 
    outcome = "CF",
    coords = tribble(
      ~ name,  ~ x, ~ y,
      "I",       1,   2,
      "CF",       3,   1,
      "Z",       1,   0,
      "V",       2,   0,
      "X",       0,   1,
      "U1",      3, 0,
      "U2",      2.25,   2
    )
  ) %>%
  tidy_dagitty(layout = "auto") %>%
  mutate(
    label = case_when(
      name == "V" ~ "Past Presidential Vote",
      name == "I" ~ "Partisan Ideology",
      name == "CF" ~ "Candidate Position",
      name == "X" ~ "Pre-Treatment Confounders",
      name == "Z" ~ "Intermediate Confounders"
    ),
    pt_label = case_when(
      name == "V" ~ "V[d]",
      name == "I" ~ "bar(theta)[g]",
      name == "CF" ~ "CF[i]",
      name == "X" ~ "X[d]",
      name == "Z" ~ "Z[d]",
      name == "U1" ~ "U1",
      name == "U2" ~ "U2"
    )
  ) %>%
  print()
```

```{r g-dags}
base_dag <- g_dag %>%
  ggplot() +
  aes(x = x, y = y, xend = xend, yend = yend) +
  coord_cartesian(ylim = c(-0.25, 2.25)) +
  theme_mgd_dag() +
  labs(x = NULL, y = NULL) +
  expand_plot(
    expand_x = expand_scale(c(0.2, 0.2)), 
    # expand_y = expand_scale(c(0.2, 0.2))
  ) +
  NULL

mediator_dag <- base_dag +
  geom_dag_point(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE),
    color = "gray"
  ) +
  geom_dag_edges(
    data_directed = filter(g_dag, name %in% c("U2", "U1") == FALSE)
  ) +
  geom_dag_text(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE), 
    aes(label = pt_label),
    parse = TRUE,
    size = 3.5,
    color = "black"
  ) +
  labs(title = "\nStage 1", subtitle = "Identifies mediator effect\n") +
  NULL

exposure_dag <- base_dag +
  geom_dag_node(
    data = filter(g_dag, name %in% c("U2", "U1") == FALSE),
    internal_color = "gray",
    color = "white"
  ) +
  geom_dag_point(
    data = filter(g_dag, name %in% c("X", "I", "CF")),
    color = "gray"
  ) +
  geom_dag_edges(
    data_directed = g_dag %>%
      filter(
        to %in% c("Z", "V") | (name == "Z" & to == "CF"), 
        name %in% c("U1", "U2") == FALSE
      ),
    edge_linetype = "dashed", 
    edge_color = "gray"
  ) +
  geom_dag_edges(
    data_directed = g_dag %>%
      filter(
        (name %in% c("U1", "U2", "Z", "V")) == FALSE, 
        to %in% c("I", "CF")
      )
  ) +
  geom_dag_text(
    data = filter(g_dag, name %in% c("U1", "U2") == FALSE),
    aes(label = ifelse(name == "CF", "b(CF)[i]", pt_label)),
    color = "black",
    parse = TRUE,
    size = 3.5
  ) +
  labs(
    title = "\nStage 2", 
    subtitle = "Identifies controlled direct effect\nof treatment using demediated outcome"
  ) +
  NULL

confounding_dag <- base_dag +
  geom_dag_point(aes(color = name %in% c("U2", "U1"))) +
  geom_dag_edges() +
  geom_dag_text(
    aes(label = pt_label), 
    parse = TRUE, 
    size = 3.5,
    color = "black"
  ) +
  theme(legend.position = "none") +
  scale_color_manual(values = c("TRUE" = primary, "FALSE" = "gray")) +
  labs(title = "Violations of Sequential Ignorability", 
       subtitle = "In stage 1 (U1) and stage 2 (U2)")
```

```{r plot-g-dag}
g_layout <- "
AABB
#CC#
"

wrap_plots(
  A = mediator_dag, B = exposure_dag, C = confounding_dag, 
  design = g_layout
)
```

Figure&nbsp;\@ref(fig:plot-g-dag) visualizes the modeling assumptions for sequential-$g$ estimation using causal graphs, which helps explain how to implement the routine. The left panel shows the stage-one model, which estimates the effect of past voting $V$ (the mediator) on candidate positioning $C$ (the outcome). This first stage conditions on district-party preferences $T$, pre-treatment confounders $X$, and intermediate confounders $Z$, all of which are necessary to identify the causal effect of the mediator. 

```{r plot-g-dag, include = TRUE, fig.width = 9, fig.height = 10, out.width = "100%", fig.cap = "Causal graphs describing the modeling problem and sequential-$g$ estimation. The stage 1 graph identifies the effect of the past district voting ($V_{d}$) on candidate positioning ($CF_{i}$). The stage 2 treatment-outcome model subtracts the district vote effect from candidate positions and identifies the effect of district-party ideology $\\bar{\\theta}_{g}$ on the demediated CF score $b(CF)_{i}$, which is equivalent to the controlled direct effect on the raw CF score. The final graph shows where unadjusted confounders violate the nonparametric causal identification assumptions in stage 1 ($U1$) and in stage 2 ($U2$)."}
```


After estimating the mediator's effect on the outcome, the outcome variable is _demediated_ by subtracting the mediator effect from the outcome variable. The center panel represents this demediation step by rewriting the outcome variable as $b(C)$, the demediated value of $C$.^[
  The exact demediation operation is shown below in Equation&nbsp;\@ref(eq:blipdown-function).
]
The stage-two model then estimates the effect of district-party preferences $T$ on the demediated candidate positions, controlling for pre-treatment covariates $X$.
Demediating the outcome suppresses the path from $V$ to $b(C)$ because (by sequential unconfoundedness) there is no longer any systematic variation between the mediator and the outcome. As such, there is no need to adjust for $V$, since it has no systematic effect on $b(C)$ after demediation. 
Furthermore, although there remains a causal effect from the intermediate confounders $Z$ to candidate positions, the stage-two model does not adjust for these confounders to avoid post-treatment bias in the estimate of the CDE.
This stage-two model recovers the controlled direct effect of $T$ on $C$.

It is worth noting here that if we estimate the stage-two model using the natural value of $C$ rather than the demediated $b(C)$, we would obtain the total effect of $T$ (the conditional average treatment effect) rather than the controlled direct effect. This can be valuable, since the difference between the total effect and the controlled direct effect are an indirect indicator of how much of the total effect flows through a mediator variable.

The final panel shows where unmeasured confounding can violate the sequential unconfoundedness assumption. The stage-one model identifies the causal effect of the mediator, so if an unmeasured variable (represented in the future by $U1$) affects both the mediator and the outcome, the mediator's effect is not identified. Similarly, the stage-two model does not identify the effect of $T$ on $b(C)$ if they share an unmeasured confounder $U2$.
Unmeasured variables in other locations of the graph certainly exist, but they do not violate sequential unconfoundedness unless they can be represented by an open back-door path through $U1$ or $U2$.^[
  For instance, a variable $W$ may be a common cause of $X$ and $C$, thus creating the path $T \rightarrow X \rightarrow W \rightarrow C$, but it does not confound the effect of $T$ because conditioning on $X$ blocks the path. 
  Additionally, although intermediate confounders $Z$ are presented as descendants of group policy ideology $T$, intermediate confounders do not necessarily have to be affected by $T$ (though they can be). They only need to be confounders of the mediator-outcome relationship.
]
There are functional form considerations however---biases may remain if the functional forms for confounders $X$ and $Z$ are inappropriate.^[
  I plan to investigate more flexible functional forms in the near future.
]
<!------- TO DO ---------
- functional forms comment
------------------------->

<!------- TO DO ---------
- way bigger emphasis on the contribution of the design.
  other analysis do this kind of observables setup, but they don't
  deal with the causal estimand and the explication of assumptions.
------------------------->

<!------- TO DO ---------
- Discuss potential violations of assumptions
- Simulate violated assumptions by way of correlated error parameters?
------------------------->

## Bayesian Sequential-$g$ Analysis

Keep the notation general enough (expectations) so that there are no explicit linear regression functional forms introduced by accident?

Identification and estimand are above?

Contribution: $\bar{\theta}_{g}$ is drawn from a prior and can be updated in the model.

ACDE is posterior distribution of the causal quantity...




<!-- As mentioned above, I estimate average controlled direct effects separately for incumbents, challengers, and open seat candidates in two parties, totaling six routines altogether.  -->
I write a general model that applies regardless of which subset of data is being used. 
Because the estimation in every data subset proceeds in two stages, I use subscript some parameters $1$ and $2$ to indicate that they are not fixed across model stages.

<!------- TO DO ---------
- separate parties
- incumbency
------------------------->

The first stage is a mediator-outcome model, predicting the CF score of candidate $i$ within group $g$, where a group is a combination of district $d$ and party. 
Because I estimate separate models for each party, each model sees data from only one group per district.
Nonetheless, I use separate $g$ and $d$ subscripts to denote which variables have the potential to vary by groups within districts.
We set up the sequential-$g$ method to control for the previous Republican presidential vote share in district $d$, denoted $\mathit{pvote}_{g}$.
This is done with the following multilevel regression model.
\begin{align}
\begin{split}
  \mathrm{CF}_{i} &= 
    a_0 + 
    \eta \bar{\theta}_{g[i]} + 
    \mu \mathrm{pvote}_{d[i]} + 
    \mathbf{x}_{d[i]}^{\intercal}\beta +
    \mathbf{z}_{d[i]}^{\intercal}\gamma +
    \alpha_{d[i]} + \epsilon_{i} \\
  \alpha_{d} &\sim \mathrm{Normal}\left(0, \sigma_{\alpha}\right) \\
  \epsilon_{i} &\sim \mathrm{Normal}\left(0, \sigma_{\epsilon}\right)
\end{split}
(\#eq:med-model)
\end{align}
This model identifies the effect of the presidential vote, $\mu$, under the identification assumption of sequential ignorability and the statistical assumptions of linearity and no interactions.
<!------- TO DO ---------
- check on these assumptions
------------------------->
The group ideal point $\bar{\theta}_{g}$ is included in the regression as a control, so the coefficient $\eta$ is estimated as a nuisance parameter, as are the coefficients $\beta$ for district-level pre-treatment confounders $\mathbf{x}_{d}$, the coefficients $\gamma$ for district-level intermediate confounders $\mathbf{z}_{d}$, and constant $a_{0}$.
Because the mediator is measured at the district level, I include a district error term $\alpha_{d}$ in addition to the candidate-level error term $\epsilon_{i}$.
The multilevel model accounts correlated error among candidates in the same district, similar to clustering standard errors when a treatment is dosed at the cluster level.


Sequential-$g$ estimates the controlled direct effect of treatment by purging the DV of the mediator effect.
This is done by predicting the outcome variable as if the mediator were fixed for all units, which purges the outcome of all systematic variation caused by the mediator variable. 
This can be done by predicting the outcome under a fixed mediator value directly or by demediating the outcome directly using an estimate of the demediation function.
Because the first stage is a linear model, the demediation function has a straightforward parametric definition,
\begin{align}
  \delta_{d} &= \mu \left(\mathrm{pvote}_{d} - \mathrm{pvote}'\right)
  (\#eq:blipdown-function)
\end{align}
where $\mathit{pvote}'$ is the reference value for the mediator where all units are fixed, and $\mu$ is the mediator's effect from Equation \@ref(eq:med-model).
The demediation function represents the effect setting district $d$'s presidential vote to its observed value compared to the reference value $\mathit{pvote}'$.
Because the previous presidential vote varies across districts, so too does the demediation function.^[
  In any case where the reference value for the mediator is zero, this expression reduces to $\mu \mathit{pvote}_{d}$, and an observed value of zero implied a demediation function of zero.
]
We choose a reference value of $0.5$, an even vote split between the Republican and Democratic presidential vote shares in the previous election.
The demediation function can be more complex if the mediator's effect on the outcome is modeled with a more complex model containing interactions or nonlinearities.
We calculate the demediated outcome $b(CF)_{i}$ by subtracting each district's demediation function from its observed outcome value,
\begin{align}
  b\left(\mathrm{CF}\right)_{i} &= \mathrm{CF}_{i} - \delta_{d}
  (\#eq:blipdown-outcome)
\end{align}
Because the mediator is fixed for a given district, all candidates in a district have the same demediation function, regardless of their original CF score.
The demediated outcome value is equivalent to the outcome under a fixed mediator value,
\begin{align}
\begin{split}
  b\left(\mathrm{CF}\right)_{i} &= \mathrm{CF}_{i} - \delta_{d} \\
  b\left(\mathrm{CF}\right)_{i} &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \mathrm{pvote}_{d[i]} + 
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} -
    \mu \left(\mathrm{pvote}_{d[i]} - \mathrm{pvote}'\right) \\
  &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \left(\mathrm{pvote}_{d[i]} - \mathrm{pvote}_{d[i]} + \mathrm{pvote}'\right) +
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
  &= 
    a_{0} + 
    \eta \bar{\theta}_{g[i]} +
    \mu \mathrm{pvote}' + 
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
  &= 
    a' + 
    \eta \bar{\theta}_{g[i]} +
    \mathbf{x}_{d[i]}^{\intercal}\beta + %_
    \mathbf{z}_{d[i]}^{\intercal}\gamma + %_
    \alpha_{d[i]} + \epsilon_{i} \\
\end{split}
(\#eq:med-model-blipped)
\end{align}
which makes it clearer to see how the demediation step subtracts the mediator variation from the outcome, absorbing the non-varying mediator into the new constant $a'$.

The demediated outcome is then used in the second stage estimation of the controlled direct effect.
The second stage is different from the first stage in two ways.
First, because we fixed the mediator value in calculating the transformed outcome variable, there is no more variation across observations that can be attributed to the mediator.
As such, it is omitted from the equation.
Second, intermediate confounders are omitted because they are unnecessary to identify the effect of district-party ideology, and they could induce collider bias if included.
This new equation is,
\begin{align}
  b\left(\mathrm{CF}\right)_{i} = 
    a_{1} +
    \tau \bar{\theta}_{g} + 
    \mathbf{x}^{\intercal}_{g[i]}\omega + 
    \nu_{d[i]} + u_{i} \\
(\#eq:trt-model)
\end{align}
where $a_{1}$ is a constant, $\tau$ is the coefficient for district-party ideology, $\omega$ are coefficients for district-level pre-treatment confounders $\mathbf{x}_{d}$, $\nu_{d}$ is a district error term, and $u_{i}$ is a candidate error term.
Because the presidential vote effect has been removed from the dependent variable, any treatment effect mediated by the presidential vote is not recoverable by the second stage equation.
As such, $\tau$ measures the average controlled direct effect of a one-unit increase in district-party ideology.
More generally, the ACDE of setting district-party ideology from $\bar{\theta}'$ to $\bar{\theta}$ is as follows.
\begin{align}
  ACDE(\tau, \bar{\theta}, \bar{\theta}') &= \tau \left(\bar{\theta} - \bar{\theta}'\right)
  (\#eq:general-ACDE)
\end{align}
Again, the formula for the ACDE depends on the model specification.
The form in \@ref(eq:general-ACDE) applies to a linear model with no interactions, but a more complex model would entail a more complex formula.


### Bayesian Contributions and Priors

<!------- TO DO ---------
- fix me
------------------------->

One important feature of this dissertation is that our causal variable of interest, the policy ideology of district-party publics, is not measured with certainty. The model in Chapter&nbsp;\@ref(ch:model) estimates this quantity up to a posterior distribution, but the variation in the posterior distribution creates an additional layer of uncertainty in our understanding of causal effects. This creates theoretical issues with the definition of treatment effects as well as practical issues for estimation, which I describe in turn.

As discussed in Chapter&nbsp;\@ref(ch:causality), it is natural to interpret causal inference as Bayesian updating about a causal parameter using models and data. Following @rubin:1978:bayesian's Bayesian interpretation of his own work with potential outcomes, causal inference is a method for generating counterfactual estimates of an outcome variable as if they were predictive draws from the posterior distribution. Supposing that we seek the causal effect of an intervention on group ideology, $\tau$, and we observe only one potential outcome, $y_{g}(\bar{\theta}_{g})$, how do we specify the posterior distribution if we set group ideology to some other value $\theta'$? Not only do we have posterior uncertainty about $\tau$, but we are also uncertain about the actual value of $\bar{\theta}_{g}$ that we observed in the first place, since the measurement model from Chapter&nbsp;\@ref(ch:model) estimates it only up to a posterior distribution. Our posterior distribution for missing potential outcomes reflects both sources of uncertainty. Econometrics refers to this problem as "errors in variables," but it takes on a special meaning when it comes to the interpretation of causal interventions, since it stresses our understanding of what an "observed" potential outcome is.

Practically, this means that we will underestimate our uncertainty about causal effects unless we can account for the uncertainty in our treatment variable on top of our uncertainty in its effect on candidate positioning. All ideal point estimates are uncertain, but not many studies confront this uncertainty. Since the usefulness of the ideal point model in Chapter&nbsp;\@ref(ch:model) is important to explore in this dissertation, it feels appropriate not to ignore posterior uncertainty in its applications. As such, I conduct all sequential-$g$ analyses below using raw posterior samples, rather than posterior means. I describe the exact routine in Section&nbsp;\@ref(sec:pos-uncertainty).

<!-- 

We observe $y_{g}\left(\bar{\theta}_{g}\right)$, but we don't know $\bar{\theta}_{g}$ with certainty. Instead let $p\left(\bar{\theta}_{g}\right)$ be the posterior distribution of $g$'s average policy ideology as estimated from the group IRT model in Chapter&nbsp;\@ref(ch:model). Our observed outcome is a function of this unknown value, which we represent as $y_{g}\left(p\left(\bar{\theta}_{g}\right)\right)$. 

Thus the causal effect of setting $\mathrm{do}\left(\theta\right)$, as opposed to some $\theta'$, for unit $g$ is
\begin{align}
  \tau_g &= y_{g}\left(\theta\right) - y_{g}\left(\bar{\theta}_{g}'\right),
\end{align}

The posterior distribution for this value is 
$p\left(\tau_{g}\right) = p\left(\right)$

or, written as a probability distribution 
\begin{align}
  p\left(\tau_{g}\right) &= p\left(y_{g}\left(\theta'\right) - y_{g}\left(\bar{\theta}_{g}\right)\right)
\end{align}

 -->



- theta is uncertain
- we need priors
- everything is one model, so instead of needing a variance correction that 

$\bar{\theta}_{g}$ is an element of $\bar{\Theta}$, the vector of all group ideal points. 
The exact value of $\bar{\theta}_{g}$ is unknown—the model in Chapter \@ref(ch:model) used survey data to update our information, but we still only have samples from the probability distribution given our current data.
This means that the $\bar{\theta}_{g}$ that the sequential-$g$ model sees are parameters with probability distributions, not fixed data.
As such, they appear in the model with a prior distribution, which is the posterior distribution from the measurement model. 
\begin{align}
  \bar{\Theta} &\sim 
    \mathrm{MultiNormal}\left( \hat{\Theta}, \hat{\Sigma}_{\Theta} \right)
  (\#eq:theta-prior)
\end{align}



### Multilevel Considerations 

The research question in this chapter presents us with multilevel data: how is the ideological positioning of primary candidates affected by the policy ideology of partisans in their district, when there are potentially multiple candidates per district?
In this scenario, the outcome is a variable specific to an individual candidate $i$, but the treatment is fixed for an entire district-partisan group $g$. 
This introduces a few issues for statistical assumptions and causal assumptions.

On the statistical front, multilevel models bias coefficient estimates when the aggregate errors are not exchangeable.
Mechanically, this is the same as "omitted variable bias" in a single-level regression: if the errors are not independent, then coefficients will be biased.
Although this concern is well founded for many multilevel models, for these models we can be less concerned.
Because all predictors in these regressions are measured at the district level, the district error term is analogous to an error term that we would obtain by averaging every candidate's CF score within a district-party group and running a single-level regression on those averages.
In other words, we make the same independence assumption either way.
The only difference for the models in this analysis is the additional candidate-level errors, but this too is a non-issue. 
Averaging candidate data within each district invokes the same exchangeability assumption as an additional error term, otherwise a simple average wouldn't make sense.

The multilevel model has additional benefits that are convenient for these data.
Because the number of candidates in a district isn't fixed across all districts, we would expect heteroskedasticity in the model residuals if we averaged the data within each district.
Furthermore, in districts with only one candidate, there is no way for a naïve estimator to separate district variance from candidate variance. 
The multilevel model addresses this by modeling the distributions of district errors and candidate errors simultaneously, enhancing the model's ability to recognize when larger district errors are caused by signal versus noise.
Errors from smaller districts borrow more information from the overall distribution of districts, downweighting the contributions of smaller districts by shrinking their errors toward zero.
This has a similar intuition as estimating a weighted least squares regression on the district-averaged data, where districts with fewer observations are given less weight to account for heteroskedasticity.
Because the multilevel model is Bayesian, the posterior distribution naturally captures the negative correlation between the size of a district error and the size of a candidate error, even if these errors are not uniquely identified from data.
In other words, the Bayesian approach facilitates a much more convenient and feasible modeling approach because the priors provide enough structure to prevent certain pathologies of clustered data.

The multilevel data also raise causal inference issues that should be clarified.
As with many causal model where treatments are assigned to clusters of observations, it makes sense to consider SUTVA as violated within a cluster: there is no way for one candidate in a district to be treated by a different district-party ideology than other candidates.^[
  Candidates may vary in their ability to perceive district-party ideology, which might better be described as an issue of treatment compliance rather than hidden versions of treatment.
]
The positioning of one candidate may also affect the positioning of another, which could violate the "no interference" component of SUTVA. 
Under this violation, the treatment effect at the individual level is not identified.
If SUTVA holds _between_ groups, however, it is possible to identify a treatment effect by considering average effects across groups [@Hill:2013:multilevel-causal-inf]. 
In potential outcomes notation, even if we can define potential outcomes at the individual level ($\mathit{CF}_{i}(\bar{\theta}_{g[i]})$), the lowest level where we could credibly identify treatment effects would be at the group level, where the potential outcome for a group is the average outcome within the group ($\overline{\mathit{CF}}_{g}\left(\bar{\theta}_{g}\right)$).
This is consistent with the multilevel model setup that we have so far, where the treatment effect is captured using district-level data and district-level predictors only (see Equation \@ref(eq:general-ACDE)).

There are a few additional considerations for causal inference with hierarchical data that, although I do not pursue these threads in this project, could be relevant for future work with similar data.
If treatment effects are correlated with group size, then the average causal effect will not be equivalent to the average difference among groups.
Instead, the average effect should be thought of as a size-weighted average of group effects [@Hill:2013:multilevel-causal-inf].
A correlation between treatment effects and group size may arise if a crowded primary field causes larger treatment effects because stiffer competition leads candidates to be more responsive to district-party ideology.
On the other hand, more crowded fields would lead to smaller treatment effects if candidates take heterogeneous ideological positions to differentiate themselves.
These dynamics are not identifiable with the raw data in this project, as incumbents may take ideological positions to deter challengers, even if no challengers actually emerge.
As such, the observed number of challengers may not capture the true degree of primary threat [@hirano-et-al:2010:primary-polarization].

One additional consideration for group-level effects is the possibility that group size affects treatment assignment.
This may indirectly be the case if the dynamics of primary competition within a district-party have feedback effects on local ideology, for instance if partisan constituents become more ideological after experiencing a history of strong primary competition in their district, or less ideological after a long period representation by one incumbent with little primary competition.
Given the still-nascent state of the research on ideological primary competition, it is safe to say that political scientists have little idea which of these propositions is more likely. 
Future researchers would make progress on these questions by extending the data and methods in this project to cover a greater number of election cycles and more detailed investigations of these causal and modeling assumptions.


<!-- If treatment is correlated with X _by design_(?) or otherwise(?), such as blocking along a key covariate like income, can include block-specific means of the treatment variable [@Hill:2013:multilevel-causal-inf]; Bafumi and Gelman, Raudenbush -->

<!-- ranefs assumption is similar to averaging w/in group...? -->



### Data



Pre-treatment confounders consist of district-level demographic indicators for the racial composition, college graduation rate, median income, inequality (Gini), unemployment rate, foreign-born population, and evangelical population, and $\mathbf{z}_{ig}$ currently contains an order-3 polynomial function of candidate $i$'s total campaign receipts.^[
  Note: this isn't a good choice for intermediate confounding, and it should change. Ask me why!
]

<!------- TO DO ---------
- should be a prior measure of relative party campaign spending
------------------------->
<!------- TO DO ---------
- justify covariates with cites?
------------------------->



<!-- Primary Candidacies -->

<!-- CF scores -->

CF scoreswork by assuming that a donor $i$ contributes to recipient $j$ by maximizing their donation utility over all potential recipients.
The donor chooses a dollar amount $y_{ij}$ subject to contribution limits that maximizes
\begin{align}
  u_{i}(\mathbf{y}_{i}) &= \sum\limits_{j} \left[
    b_{i}\left(y_{ij}\right) - y_{ij}\left(\theta_{i} - \delta_{j}\right)^2
  \right]
\end{align}
where $b_{i}(y_{ij})$ is $i$'s net benefit for contribution $y_{ij}$ (instrumental and/or expressive benefits minus costs), $\theta_{i}$ is the donor's ideal point, and $\delta_{j}$ is the recipient's ideal point.
The term $y_{ij}\left(\theta_{i} - \delta_{j}\right)^2$ is a dollar-weighted function of the ideological distance between donor and candidate ideologies.
The term grows when the ideological distance is greater, meaning that the donor loses more utility by giving to candidates that don't reflect the donor's ideological preferences, and it also grows when the donation amount $y_{ij}$ is larger.
The $b_{i}$ function acts like a donor-level fixed effect, capturing a donor's overall propensity to donate regardless of their ideological proximity to potential recipients.
@bonica:2013:ideology-interests derives a fully parameterized item response theory (IRT) model from this utility framework, estimating latent ideological locations for all donors and all recipients from their contribution patterns.
The IRT scores do not cover as wide of a universe as CF the scores created from correspondence analysis [@bonica:2014:mapping-ideology]. 

<!------- TO DO ---------
- validity conversation!!!
------------------------->



<!-- ### Primary Rules -->

General comment: very difficult to code these.

- law vs. party rules
- for some organizations "open" means there's ANY openness, which can include the McGhee "semi-closed" definition
- most states have the same system for both parties, but some state laws leave it open to parties to modify their rules in the months leading up to the election. 


I take data from Boatright on primaries. 

- 2016: combination of NCSL, Ballotpedia, and OpenPrimaries.org, as of 2020-05-27.


`r knit_exit()`

### Move me

```{r read-g, eval = FALSE}
g_samples <- 
  here("data", "_model-output", "04-positioning", "pos-g-samples.rds") %>%
  read_rds() %>%
  print()
```

```{r unnest-samples, eval = FALSE}
mediator_samples <- g_samples %>%
  select(party, incumbency, .draw, mediator_samples) %>%
  unnest(cols = mediator_samples) %>%
  ungroup() %>%
  mutate(
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()

direct_samples <- g_samples %>%
  select(party, incumbency, .draw, direct_samples) %>%
  unnest(cols = direct_samples) %>%
  ungroup() %>%
  mutate(
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()

total_samples <- g_samples %>%
  select(party, incumbency, .draw, direct_samples, total_samples) %>%
  unnest(cols = c(total_samples, direct_samples)) %>%
  ungroup() %>%
  mutate(
    indirect_effect = total_effect - direct_effect,
    incumbency = str_glue("{incumbency}s")
  ) %>%
  print()
```

I implement the sequential-$g$ routine using candidate data drawn primarily from @bonica:2019:dime, @foster-molina:2016:data, and my own estimates. 

For the dependent variable, I use Bonica's dynamic Dime scores for House primary candidates in election years 2012, 2014, and 2016. These estimates are generated from a data reduction on campaign contributions data, assuming that campaign contributors give money to ideologically proximate candidates.

For the mediator, I use the Republican share of the presidential vote in the prior election, available in the Bonica data for each candidate running for House. This serves as a broad measure of district voting that closely reflects the partisan composition of the district.

For my independent variable, I use my own district-party ideology estimates generated for the post-2012 districting cycle, estimated from ANES and CCES data for years 2012 through 2018.^[
  One feature in this design that needs improvement is that it would be nice to have ideology estimates that evolve more over time, so as not to treat district-party ideology as fixed for an entire redistricting cycle, which is the current setup of the model.
]

Control variables are measured primarily at the congressional district level and are drawn primarily from @foster-molina:2016:data. These covariates include racial, educational, religious, and economic features of districts, which I revisit below. Currently I do not have data on primary institutions included in the routine, which limits what I can say about effect modification in primaries vs. caucuses or as a function of primary openness. This is an important part of the story to include in the future. 



### Full Model



### Algorithm {#sec:pos-uncertainty}

<!------- TO DO ---------
- How is the model set up in Stan
- propagating uncertainty
------------------------->

Because the demediated outcome value in stage two depends on parameter estimates from stage one, our average controlled direct estimate $\tau_{2}$ should reflect parameter uncertainty from both stages. @acharya-blackwell-sen:2016:direct-effects derive an analytical variance estimator that deals with this, but unfortunately this estimator does not incorporate the additional uncertainty introduced by the fact that the key independent variable, district-party ideology, is an estimate from a separate measurement model. To overcome this, I implement a simulation routine that propagates model uncertainty from the ideal point estimate into both stages, as well as stage one uncertainty into the second stage. 

Suppose that we had a matrix of ideal point samples $\Theta$ that had one row for every district-party group and one column for every Markov chain Monte Carlo iteration from the estimation in Chapter&nbsp;\@ref(ch:model). We begin by drawing a set of $m$ columns from this matrix, and then for each column $m$ we perform the following routine:^[
  The index $m$ represents one MCMC iteration, with all parameters from that iteration sampled simultaneously. This deals with the fact that ideal point parameters will be correlated within iteration, so they should be supplied to the sequential-$g$ algorithm together.
]

- Estimate the mediator model using the sampled ideal point.
- To carry uncertainty forward from the mediator model, sample 1 coefficient draw from the implied posterior distribution for the mediator effect. This results in a random draw of the mediator effect that combines the uncertainty in the district-party ideal points with the uncertainty in the mediator's effect on the outcome.
- Use each sampled mediator effect to demediate the dependent variable. The demediated value reflects uncertainty in the mediator effect and in the initial ideal point draw.
- Use the demediated outcome to estimate the average controlled direct effect of district-party ideology. Sample one ACDE draw from the implied posterior and store it. 

This routine was performed for $m = `r smart_number(length(unique(direct_samples$.draw)))`$ ideal point draws, so the result is a distribution of `r smart_number(length(unique(direct_samples$.draw)))` ACDE simulations that reflect measurement uncertainty in district-party ideology as well as modeling uncertainty in both stages of sequential-$g$.



## Findings

### District-Party Ideology and Primary Candidate Positioning

I'm running short on time to write these results up gracefully, but here's what we're seeing so far!

```{r g-summaries, eval = FALSE}
mediator_summary <- mediator_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(mediator_effect), 
    conf.low = quantile(mediator_effect, .05), 
    conf.high = quantile(mediator_effect, .95),
    n_samples = n()
  ) %>%
  print()

direct_summary <- direct_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(direct_effect), 
    conf.low = quantile(direct_effect, .05), 
    conf.high = quantile(direct_effect, .95),
    n_samples = n()
  ) %>%
  print()

total_summary <- total_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(total_effect), 
    conf.low = quantile(total_effect, .05), 
    conf.high = quantile(total_effect, .95),
    n_samples = n()
  ) %>%
  print()

indirect_summary <- total_samples %>%
  group_by(party, incumbency) %>% 
  summarize(
    sample_mean = mean(total_effect - direct_effect), 
    conf.low = quantile(total_effect - direct_effect, .05), 
    conf.high = quantile(total_effect - direct_effect, .95),
    n_samples = n()
  ) %>%
  print()
```

### Stage 1


```{r, eval = FALSE}
ggplot(mediator_samples) +
  aes(x = mediator_effect) +
  geom_histogram(
    aes(fill = as.factor(party), color = as.factor(party)), 
    position = "identity", alpha = 0.5, bins = 50,
    show.legend = FALSE
  ) +
  facet_wrap( ~ incumbency) +
  scale_fill_manual(values = party_factor_colors) +
  scale_color_manual(values = party_factor_colors)
```

```{r plot-mediator, eval = FALSE}
ggplot(mediator_samples) +
  aes(
    x = mediator_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  # geom_vline(xintercept = 0, color = "gray", size = 0.5) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = mediator_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = mediator_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside"
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.75)) +
  labs(
    title = "Effect of Past Presidential Vote", 
    subtitle = "On Candidate Dime Score",
    y = NULL, x = NULL
  ) +
  NULL
```


Stage 1 estimates the previous presidential vote's effect on candidate ideal points (the mediator-outcome model). Mediator effects in Figure&nbsp;\@ref(fig:plot-mediator) show noisy estimates. A one-unit represents a 100 percent change in Republican vote, whereas most Dime scores for candidates live in the [-2, 2] range. So this regression is getting hardly any signal from the presidential vote. 

This maybe isn't so crazy, since most of the votes vs. ideal point relationship is between rather than within parties. This echoes back to a key finding in [@mccarty-poole-rosenthal:2009:gerrymandering], that the within-party relationship between district vote shares and NOMINATE scores was actually quite weak! It appears that these data find an even weaker relationship between district votes and Dime scores.


```{r plot-mediator, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE,  out.width = "100%", fig.cap = "Mediator findings"}
```

### Stage 2



```{r plot-direct, eval = FALSE}
ggplot(direct_samples) +
  aes(
    x = direct_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  geom_vline(
    xintercept = 0, color = "gray", size = 0.5, linetype = "dashed"
  ) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = direct_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = direct_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside",
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.25)) +
  labs(
    title = "Effects of District-Party Ideology",
    subtitle = "Controlled Direct Effect on Candidate Dime Score",
    y = NULL,
    x = NULL
  ) +
  NULL
```

We're seeing average controlled direct effects that are statistically noteworthy in Figure&nbsp;\@ref(fig:plot-direct). Error bars represent 90 percent intervals,^[
  90 percent intervals are chosen because simulation-based statistics they are more stable estimators of the interval bounds than 95 percent intervals, especially when we don't have a huge number of iterations to work with. 
]
which means that most of our simulations are showing ACDEs that have 95 percent posterior probability above zero. I know that I need to do some rescaling of variables to make these effects more interpretable, and once I do that I will be able to put regularizing priors on these effects so as to guard against overfitting in the inference of the treatment effect. 


```{r plot-direct, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE, out.width = "100%", fig.cap = "ACDE findings"}
```





```{r plot-indirect, eval = FALSE}
ggplot(total_samples) +
  aes(
    x = indirect_effect, y = as.factor(party), 
    fill = as.factor(party), color = as.factor(party)
  ) +
  geom_vline(
    xintercept = 0, color = "gray", size = 0.5, linetype = "dashed"
  ) +
  # annotate(
  #   geom = "segment", x = 0, xend = 0, y = 0, yend = 3.25,
  #   color = "gray"
  # ) +
  geom_segment(
    data = indirect_summary,
    aes(x = conf.low, xend = conf.high, 
        y = as.factor(party), yend = as.factor(party))
  ) +
  geom_point(
    data = indirect_summary, aes(x = sample_mean, y = as.factor(party))
  ) +
  ggridges::geom_ridgeline(
    stat = "binline", draw_baseline = FALSE,
    boundary = 0, bins = 40, scale = 0.4,
    alpha = 0.25
  ) +
  facet_wrap(~ incumbency, nrow = 1, strip.position = "bottom") +
  scale_color_manual(values = party_factor_colors) +
  scale_fill_manual(values = party_factor_colors) +
  scale_y_discrete(
    breaks = c(1, 2), labels = c("Democrats", "Republicans")
  ) +
  theme(
    legend.position = "none",
    panel.border = element_blank(),
    panel.background = element_blank(),
    axis.line.x = element_line(),
    axis.ticks.y = element_blank(),
    strip.placement = "outside",
    # axis.text.y = element_blank()
  ) +
  coord_cartesian(ylim = c(1.35, 2.25)) +
  labs(
    title = "Strength of the District Vote Mechanism",
    subtitle = "Total Effect minus Controlled Direct Effect of District-Party Ideology",
    y = NULL,
    x = NULL
  ) +
  NULL
```

```{r plot-indirect, include = TRUE, fig.width = 7, fig.height = 3, eval = FALSE, out.width = "100%", fig.cap = "ATE-ACDE findings"}
```

<!------- TO DO ---------
- parameter constraints!
    - total = direct + indirect
    - p(total) and p(direct), which are estimated, implying a prior for p(indirect).
    - Suppose we constrain the variance of one of these, which of the "free" priors gets a better signal?
------------------------->


### Primary Rules



## Points of Improvement

### Primary Representation

The DAG reveals how confounding affects this conclusion.

- if intermediary groups are the key voice, but intermediaries are sampled from the population, then the population has an effect.
- if the population responds to intermediaries (which might instead be functions of industry, demographics, etc), then the causal effect remains confounded insofar as controlling for demographics does _not_ do a sufficient job.
- draw a dag:
    - positioning ~ ideology, EPN
    - ideology ~ EPN, demographics
    - EPN ~ demographics + u
    - if U also connects to positioning, we're in trouble?


### Bayesian Causal Inference

Flexible sequential-$g$. 




